# π€ **RBE SLLM API μ„λ²„ κ°€μ΄λ“**

## π“– **κ°μ”**

**RBE (Riemannian Basis Encoding) SLLM API μ„λ²„**λ” ν‘Έμ•µμΉ΄λ  λ³Ό κΈ°λ°μ νμ‹ μ μΈ λ¨λΈ μ••μ¶• κΈ°μ μ„ ν™μ©ν•μ—¬ μ†ν• μ–Έμ–΄ λ¨λΈμ ν¨μ¨μ μΈ μ¶”λ΅ μ„ μ κ³µν•©λ‹λ‹¤.

### **ν•µμ‹¬ κΈ°λ¥**
- π—οΈ **κ·Ήν• μ••μ¶•**: 100:1 μ΄μƒμ μ••μ¶•λ¥ λ΅ λ¨λΈ ν¬κΈ° μ¶•μ†
- β΅ **κ³ μ† μ¶”λ΅ **: μ••μ¶•λ λ¨λΈλ΅ μ‹¤μ‹κ°„ ν…μ¤νΈ μƒμ„±
- π― **κ³ ν’μ§ μ μ§€**: RMSE < 0.001λ΅ μ›λ³Έ μ„±λ¥ μ μ§€
- π **REST API**: μ›Ή μ„λΉ„μ¤ ν•νƒμ κ°„νΈν• μ ‘κ·Ό
- π“ **μ„±λ¥ λ²¤μΉλ§ν¬**: μ••μ¶• λ° μ¶”λ΅  μ„±λ¥ μΈ΅μ •

---

## π”§ **μ„λ²„ μ‹μ‘**

### **κΈ°λ³Έ μ‹¤ν–‰**
```bash
cargo run --bin rbe-server
```

### **μµμ… μ„¤μ •**
```bash
cargo run --bin rbe-server -- \
  --host 0.0.0.0 \
  --port 8080 \
  --max-tokens 100 \
  --temperature 0.7 \
  --top-p 0.9
```

### **μ„λ²„ μ„¤μ • μµμ…**
| μµμ… | κΈ°λ³Έκ°’ | μ„¤λ… |
|------|--------|------|
| `--host` | `0.0.0.0` | μ„λ²„ νΈμ¤νΈ μ£Όμ† |
| `--port` | `8080` | μ„λ²„ ν¬νΈ λ²νΈ |
| `--max-tokens` | `100` | μµλ€ μƒμ„± ν† ν° μ |
| `--temperature` | `0.7` | κΈ°λ³Έ temperature κ°’ |
| `--top-p` | `0.9` | κΈ°λ³Έ top-p κ°’ |
| `--no-cors` | `false` | CORS λΉ„ν™μ„±ν™” |

---

## π **API μ—”λ“ν¬μΈνΈ**

### **1. ν—¬μ¤μ²΄ν¬**

μ„λ²„ μƒνƒλ¥Ό ν™•μΈν•©λ‹λ‹¤.

**μ”μ²­**
```http
GET /health
```

**μ‘λ‹µ**
```json
{
  "status": "healthy",
  "service": "RBE API Server"
}
```

**cURL μμ‹**
```bash
curl http://localhost:8080/health
```

---

### **2. λ¨λΈ μ •λ³΄ μ΅°ν**

ν„μ¬ λ΅λ“λ λ¨λΈμ μ •λ³΄λ¥Ό μ΅°νν•©λ‹λ‹¤.

**μ”μ²­**
```http
GET /model/info
```

**μ‘λ‹µ** (λ¨λΈ λ΅λ“λ¨)
```json
{
  "name": "kogpt2-base-v2",
  "compression_ratio": 128.5,
  "average_rmse": 0.0008,
  "vocab_size": 50257,
  "hidden_size": 768,
  "num_layers": 12,
  "loaded_at": "2024-01-15 10:30:45 UTC"
}
```

**μ‘λ‹µ** (λ¨λΈ μ—†μ)
```json
{
  "error": "λ¨λΈμ΄ λ΅λ“λμ§€ μ•μ•μµλ‹λ‹¤",
  "code": 404
}
```

**cURL μμ‹**
```bash
curl http://localhost:8080/model/info
```

---

### **3. λ¨λΈ λ΅λ”©**

μ••μ¶•λ RBE λ¨λΈμ„ μ„λ²„μ— λ΅λ”©ν•©λ‹λ‹¤.

**μ”μ²­**
```http
POST /model/load
Content-Type: application/json

{
  "compressed_model_path": "./models/kogpt2_rbe.json",
  "original_model_path": "./models/kogpt2-base-v2"
}
```

**μ‘λ‹µ** (μ„±κ³µ)
```json
{
  "success": true,
  "message": "λ¨λΈμ΄ μ„±κ³µμ μΌλ΅ λ΅λ“λμ—μµλ‹λ‹¤",
  "model_info": {
    "name": "kogpt2-base-v2",
    "compression_ratio": 128.5,
    "average_rmse": 0.0008,
    "vocab_size": 50257,
    "hidden_size": 768,
    "num_layers": 12,
    "loaded_at": "2024-01-15 10:30:45 UTC"
  }
}
```

**cURL μμ‹**
```bash
curl -X POST http://localhost:8080/model/load \
  -H "Content-Type: application/json" \
  -d '{
    "compressed_model_path": "./models/kogpt2_rbe.json",
    "original_model_path": "./models/kogpt2-base-v2"
  }'
```

---

### **4. λ¨λΈ μ••μ¶•**

μ›λ³Έ λ¨λΈμ„ RBE λ°©μ‹μΌλ΅ μ••μ¶•ν•©λ‹λ‹¤.

**μ”μ²­**
```http
POST /model/compress
Content-Type: application/json

{
  "model_path": "./models/kogpt2-base-v2",
  "output_path": "./models/kogpt2_rbe.json",
  "compression_level": 3,
  "block_size": 32
}
```

**μ”μ²­ νλΌλ―Έν„°**
| νλΌλ―Έν„° | νƒ€μ… | ν•„μ | κΈ°λ³Έκ°’ | μ„¤λ… |
|----------|------|------|--------|------|
| `model_path` | string | β… | - | μ••μ¶•ν•  μ›λ³Έ λ¨λΈ κ²½λ΅ |
| `output_path` | string | β… | - | μ••μ¶•λ λ¨λΈ μ¶λ ¥ κ²½λ΅ |
| `compression_level` | number | β | 3 | μ••μ¶• λ λ²¨ (1-5) |
| `block_size` | number | β | 32 | λΈ”λ΅ ν¬κΈ° |

**μ‘λ‹µ** (μ„±κ³µ)
```json
{
  "success": true,
  "message": "λ¨λΈμ΄ μ„±κ³µμ μΌλ΅ μ••μ¶•λμ—μµλ‹λ‹¤",
  "compression_ratio": 128.5,
  "compression_time_seconds": 45.2
}
```

**cURL μμ‹**
```bash
curl -X POST http://localhost:8080/model/compress \
  -H "Content-Type: application/json" \
  -d '{
    "model_path": "./models/kogpt2-base-v2",
    "output_path": "./models/kogpt2_rbe.json",
    "compression_level": 4
  }'
```

---

### **5. ν…μ¤νΈ μƒμ„±** β­

μ••μ¶•λ λ¨λΈλ΅ ν…μ¤νΈλ¥Ό μƒμ„±ν•©λ‹λ‹¤.

**μ”μ²­**
```http
POST /generate
Content-Type: application/json

{
  "prompt": "μ•λ…•ν•μ„Έμ”, μ¤λ λ‚ μ”¨λ”",
  "max_tokens": 50,
  "temperature": 0.7,
  "top_p": 0.9,
  "stream": false
}
```

**μ”μ²­ νλΌλ―Έν„°**
| νλΌλ―Έν„° | νƒ€μ… | ν•„μ | κΈ°λ³Έκ°’ | μ„¤λ… |
|----------|------|------|--------|------|
| `prompt` | string | β… | - | μƒμ„±ν•  ν…μ¤νΈμ μ‹μ‘ ν”„λ΅¬ν”„νΈ |
| `max_tokens` | number | β | 100 | μµλ€ μƒμ„± ν† ν° μ |
| `temperature` | number | β | 0.7 | μ°½μμ„± μ΅°μ  (0.0-2.0) |
| `top_p` | number | β | 0.9 | λ‹¤μ–‘μ„± μ΅°μ  (0.0-1.0) |
| `stream` | boolean | β | false | μ¤νΈλ¦¬λ° μ‘λ‹µ μ—¬λ¶€ |

**μ‘λ‹µ**
```json
{
  "text": "μ•λ…•ν•μ„Έμ”, μ¤λ λ‚ μ”¨λ” λ§‘κ³  λ”°λ»ν•©λ‹λ‹¤. μ‚°μ±…ν•κΈ° μΆ‹μ€ λ‚ μ”¨λ„¤μ”.",
  "tokens_generated": 23,
  "generation_time_ms": 450,
  "tokens_per_second": 51.1
}
```

**cURL μμ‹**
```bash
curl -X POST http://localhost:8080/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "μ•λ…•ν•μ„Έμ”, μ¤λ λ‚ μ”¨λ”",
    "max_tokens": 50,
    "temperature": 0.8
  }'
```

**Python μμ‹**
```python
import requests

response = requests.post(
    "http://localhost:8080/generate",
    json={
        "prompt": "ν•κµ­μ μ „ν†µ μμ‹ μ¤‘μ—μ„",
        "max_tokens": 100,
        "temperature": 0.7
    }
)
print(response.json()["text"])
```

**JavaScript μμ‹**
```javascript
const response = await fetch('http://localhost:8080/generate', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    prompt: 'μΈκ³µμ§€λ¥μ λ―Έλλ”',
    max_tokens: 80,
    temperature: 0.6
  })
});
const result = await response.json();
console.log(result.text);
```

---

### **6. μ„±λ¥ λ²¤μΉλ§ν¬**

μ••μ¶• λ° μ¶”λ΅  μ„±λ¥μ„ μΈ΅μ •ν•©λ‹λ‹¤.

**μ”μ²­**
```http
POST /benchmark
Content-Type: application/json

{
  "matrix_sizes": [[256, 256], [512, 512], [1024, 1024]],
  "iterations": 10
}
```

**μ”μ²­ νλΌλ―Έν„°**
| νλΌλ―Έν„° | νƒ€μ… | ν•„μ | κΈ°λ³Έκ°’ | μ„¤λ… |
|----------|------|------|--------|------|
| `matrix_sizes` | array | β | `[[256,256], [512,512], [1024,1024]]` | ν…μ¤νΈν•  ν–‰λ ¬ ν¬κΈ°λ“¤ |
| `iterations` | number | β | 10 | λ°λ³µ μΈ΅μ • νμ |

**μ‘λ‹µ**
```json
{
  "success": true,
  "message": "λ²¤μΉλ§ν¬κ°€ μ„±κ³µμ μΌλ΅ μ™„λ£λμ—μµλ‹λ‹¤"
}
```

**cURL μμ‹**
```bash
curl -X POST http://localhost:8080/benchmark \
  -H "Content-Type: application/json" \
  -d '{
    "iterations": 5,
    "matrix_sizes": [[512, 512], [1024, 1024]]
  }'
```

---

## π¨ **μ—λ¬ μ²λ¦¬**

### **κ³µν†µ μ—λ¬ μ‘λ‹µ ν•μ‹**
```json
{
  "error": "μ—λ¬ λ©”μ‹μ§€",
  "code": 500
}
```

### **μ£Όμ” μ—λ¬ μ½”λ“**
| μ½”λ“ | μ„¤λ… | ν•΄κ²° λ°©λ²• |
|------|------|-----------|
| `404` | λ¨λΈμ΄ λ΅λ“λμ§€ μ•μ | `/model/load` μ—”λ“ν¬μΈνΈλ΅ λ¨λΈ λ¨Όμ € λ΅λ“ |
| `500` | μ„λ²„ λ‚΄λ¶€ μ¤λ¥ | λ΅κ·Έ ν™•μΈ ν›„ μ„λ²„ μ¬μ‹μ‘ |
| `400` | μλ»λ μ”μ²­ | μ”μ²­ ν•μ‹ λ° νλΌλ―Έν„° ν™•μΈ |

---

## π“ **μ„±λ¥ νΉμ§•**

### **μ••μ¶• μ„±λ¥**
- **μ••μ¶•λ¥ **: 50:1 ~ 200:1
- **ν’μ§**: RMSE < 0.001 (SκΈ‰)
- **μ†λ„**: 1GB λ¨λΈ κΈ°μ¤€ ~30μ΄

### **μ¶”λ΅  μ„±λ¥**
- **μ§€μ—°μ‹κ°„**: ν† ν°λ‹Ή ~10ms
- **μ²λ¦¬λ‰**: μ΄λ‹Ή 100 ν† ν°
- **λ©”λ¨λ¦¬**: μ›λ³Έ λ€λΉ„ 99% μ μ•½

### **μ§€μ› λ¨λΈ**
- β… GPT-2 κ³„μ—΄ (KoGPT-2, GPT-2 base/medium)
- β… BERT κ³„μ—΄ (KoBERT, BERT base)
- β… T5 κ³„μ—΄ (KoT5, T5 small)
- π”„ LLaMA κ³„μ—΄ (κ°λ° μ¤‘)

---

## π› οΈ **CLI λ„κµ¬**

### **λ¨λΈ λ‹¤μ΄λ΅λ“**
```bash
cargo run --bin rbe-cli download skt/kogpt2-base-v2
```

### **λ¨λΈ μ••μ¶•**
```bash
cargo run --bin rbe-cli compress \
  ./models/kogpt2-base-v2 \
  ./models/kogpt2_rbe.json \
  --level 4 \
  --coefficients 500
```

### **ν…μ¤νΈ μƒμ„±**
```bash
cargo run --bin rbe-cli generate \
  ./models/kogpt2_rbe.json \
  ./models/kogpt2-base-v2 \
  "μ•λ…•ν•μ„Έμ”" \
  --max-tokens 50
```

### **μ„±λ¥ λ²¤μΉλ§ν¬**
```bash
cargo run --bin rbe-cli benchmark --iterations 10 --save results.json
```

### **λ¨λΈ μ •λ³΄ ν™•μΈ**
```bash
cargo run --bin rbe-cli info ./models/kogpt2_rbe.json
```

---

## π”— **ν†µν•© μμ‹**

### **μ „μ²΄ μ›ν¬ν”λ΅μ°**
```bash
# 1. μ„λ²„ μ‹μ‘
cargo run --bin rbe-server &

# 2. λ¨λΈ λ‹¤μ΄λ΅λ“
cargo run --bin rbe-cli download skt/kogpt2-base-v2

# 3. λ¨λΈ μ••μ¶•
curl -X POST http://localhost:8080/model/compress \
  -H "Content-Type: application/json" \
  -d '{
    "model_path": "./models/skt-kogpt2-base-v2",
    "output_path": "./models/kogpt2_rbe.json"
  }'

# 4. λ¨λΈ λ΅λ”©
curl -X POST http://localhost:8080/model/load \
  -H "Content-Type: application/json" \
  -d '{
    "compressed_model_path": "./models/kogpt2_rbe.json",
    "original_model_path": "./models/skt-kogpt2-base-v2"
  }'

# 5. ν…μ¤νΈ μƒμ„±
curl -X POST http://localhost:8080/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "ν•κµ­μ–΄ μμ—°μ–΄ μ²λ¦¬μ λ―Έλλ”",
    "max_tokens": 100
  }'
```

---

## π“ **μ¶”κ°€ λ¦¬μ†μ¤**

- π“– [RBE μ›λ¦¬ μ„¤λ…](../paper/PAPER_POINCARE_RBE.md)
- π”¬ [μν•™μ  λ°°κ²½](../paper/12_11λΉ„νΈ_λ―Έλ¶„_μ‚¬μ΄ν΄_128λΉ„νΈ_ν‘Έμ•µμΉ΄λ λ³Ό_μν•™μ _ν‘ν„.md)
- β΅ [μ„±λ¥ μµμ ν™” κ°€μ΄λ“](./PERFORMANCE_REPORT.md)
- π§ [ν…μ¤νΈ μΌ€μ΄μ¤](../tests/)

---

## π¤ **μ§€μ› λ° λ¬Έμ**

- π“§ μ΄λ©”μΌ: support@rbe-llm.ai
- π“± GitHub: https://github.com/your-org/rbe-llm
- π’¬ Discord: https://discord.gg/rbe-llm

**Happy RBE Coding! π€** 