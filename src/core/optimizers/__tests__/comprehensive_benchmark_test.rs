use crate::core::{
    packed_params::packed_types::Packed128,
    optimizers::{
        hybrid::HybridOptimizer,
        auto_diff::{RBETensor, ComputationGraph, RBEOperation},
        bit_autodiff::{BitTensor, BitGradientTracker},
        bit_dp_autodiff::{BitDPTensor},
        cycle_differential::CycleState,
    },
};
use std::time::Instant;
use std::collections::HashMap;

/// ì¢…í•© ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
#[derive(Debug, Clone)]
pub struct ComprehensiveBenchmarkResults {
    /// ìˆ˜ë™ ìµœì í™” ê²°ê³¼
    pub manual_results: OptimizationResults,
    /// ê¸°ì¡´ f32 ìë™ë¯¸ë¶„ ê²°ê³¼  
    pub f32_autodiff_results: OptimizationResults,
    /// ë¹„íŠ¸ ìë™ë¯¸ë¶„ ê²°ê³¼
    pub bit_autodiff_results: OptimizationResults,
    /// ë¹„íŠ¸ DP ìë™ë¯¸ë¶„ ê²°ê³¼
    pub bit_dp_autodiff_results: OptimizationResults,
    /// ë¹„êµ ë¶„ì„
    pub analysis: PerformanceAnalysis,
}

/// ê°œë³„ ìµœì í™” ê²°ê³¼
#[derive(Debug, Clone)]
pub struct OptimizationResults {
    /// ì´ ì‹¤í–‰ ì‹œê°„ (ë§ˆì´í¬ë¡œì´ˆ)
    pub total_time_us: f64,
    /// í‰ê·  ì†ì‹¤ê°’
    pub average_loss: f32,
    /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë°”ì´íŠ¸)
    pub memory_usage_bytes: usize,
    /// ì²˜ë¦¬ ì†ë„ (iterations/second)
    pub throughput_ips: f64,
    /// ì •í™•ë„ (ìˆ˜ë ´ë¥ )
    pub convergence_rate: f64,
    /// ìˆ˜ì¹˜ì  ì•ˆì •ì„± ì ìˆ˜
    pub numerical_stability: f32,
}

/// ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼
#[derive(Debug, Clone)]
pub struct PerformanceAnalysis {
    /// ë¹„íŠ¸ ìë™ë¯¸ë¶„ vs ìˆ˜ë™ ìµœì í™” ì†ë„ ë¹„ìœ¨
    pub bit_vs_manual_speedup: f64,
    /// ë¹„íŠ¸ ìë™ë¯¸ë¶„ vs f32 ìë™ë¯¸ë¶„ ì†ë„ ë¹„ìœ¨
    pub bit_vs_f32_speedup: f64,
    /// ì •í™•ë„ ê°œì„ ë¥ 
    pub accuracy_improvement_percent: f64,
    /// ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ ë¥ 
    pub memory_efficiency_improvement: f64,
    /// ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ (0-100)
    pub overall_performance_score: f32,
}

fn í…ŒìŠ¤íŠ¸_ë°ì´í„°_ìƒì„±_ëŒ€ìš©ëŸ‰(count: usize) -> Vec<(Packed128, Vec<f32>, Vec<f32>)> {
    (0..count)
        .map(|i| {
            let packed = Packed128 {
                hi: 0x123456789ABCDEF0 ^ (i as u64),
                lo: ((i as f32 * 0.01).sin().to_bits() as u64) | 
                    (((i as f32 * 0.02).cos().to_bits() as u64) << 32),
            };
            
            // 64x64 = 4096ê°œ ìš”ì†Œ (í° í–‰ë ¬)
            let mut target = Vec::with_capacity(4096);
            let mut predicted = Vec::with_capacity(4096);
            
            for j in 0..4096 {
                let x = (i + j) as f32 * 0.001;
                target.push(x.sin() * x.cos());
                predicted.push(x.sin() * x.cos() * 0.95 + 0.05); // ì•½ê°„ì˜ ì˜¤ì°¨
            }
            
            (packed, target, predicted)
        })
        .collect()
}

fn ì‚¬ì´í´_ìƒíƒœ_ìƒì„±(count: usize) -> Vec<CycleState> {
    (0..count)
        .map(|i| CycleState::from_bits((i % 2048) as u16))
        .collect()
}

#[test]
fn ì¢…í•©_ì„±ëŠ¥_ë²¤ì¹˜ë§ˆí¬_í…ŒìŠ¤íŠ¸() {
    println!("ğŸš€ RBE ìµœì í™” ë°©ë²• ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘");
    println!("   ë¹„êµ ëŒ€ìƒ: ìˆ˜ë™ ìµœì í™” vs f32 ìë™ë¯¸ë¶„ vs ë¹„íŠ¸ ìë™ë¯¸ë¶„");
    
    let test_data = í…ŒìŠ¤íŠ¸_ë°ì´í„°_ìƒì„±_ëŒ€ìš©ëŸ‰(50); // 50ê°œ * 4096 = 204,800 ìš”ì†Œ
    let cycle_states = ì‚¬ì´í´_ìƒíƒœ_ìƒì„±(4096);
    let iterations = 5; // ì¶©ë¶„í•œ ë°˜ë³µ
    
    println!("   í…ŒìŠ¤íŠ¸ ê·œëª¨: {}ê°œ ìƒ˜í”Œ, {}íšŒ ë°˜ë³µ", test_data.len(), iterations);
    println!("   í–‰ë ¬ í¬ê¸°: 64x64 (4096 ìš”ì†Œ)");
    
    // 1. ìˆ˜ë™ ìµœì í™” ë²¤ì¹˜ë§ˆí¬
    println!("\nğŸ“Š 1. ìˆ˜ë™ ìµœì í™” ë²¤ì¹˜ë§ˆí¬...");
    let manual_results = ìˆ˜ë™_ìµœì í™”_ë²¤ì¹˜ë§ˆí¬(&test_data, iterations);
    
    // 2. f32 ìë™ë¯¸ë¶„ ë²¤ì¹˜ë§ˆí¬  
    println!("\nğŸ“Š 2. f32 ìë™ë¯¸ë¶„ ë²¤ì¹˜ë§ˆí¬...");
    let f32_autodiff_results = f32_ìë™ë¯¸ë¶„_ë²¤ì¹˜ë§ˆí¬(&test_data, iterations);
    
    // 3. ë¹„íŠ¸ ìë™ë¯¸ë¶„ ë²¤ì¹˜ë§ˆí¬
    println!("\nğŸ“Š 3. ë¹„íŠ¸ ìë™ë¯¸ë¶„ ë²¤ì¹˜ë§ˆí¬...");
    let bit_autodiff_results = ë¹„íŠ¸_ìë™ë¯¸ë¶„_ë²¤ì¹˜ë§ˆí¬(&test_data, &cycle_states, iterations);
    
    // 4. ë¹„íŠ¸ DP ìë™ë¯¸ë¶„ ë²¤ì¹˜ë§ˆí¬ (ğŸš€ ìƒˆë¡œìš´ DP ì•Œê³ ë¦¬ì¦˜)
    println!("\nğŸ“Š 4. ë¹„íŠ¸ DP ìë™ë¯¸ë¶„ ë²¤ì¹˜ë§ˆí¬...");
    let bit_dp_autodiff_results = ë¹„íŠ¸_DP_ìë™ë¯¸ë¶„_ë²¤ì¹˜ë§ˆí¬(&test_data, &cycle_states, iterations);
    
    // 5. ì¢…í•© ë¶„ì„
    let analysis = ì„±ëŠ¥_ë¶„ì„_ìˆ˜í–‰_í™•ì¥(&manual_results, &f32_autodiff_results, &bit_autodiff_results, &bit_dp_autodiff_results);
    
    let comprehensive_results = ComprehensiveBenchmarkResults {
        manual_results: manual_results.clone(),
        f32_autodiff_results: f32_autodiff_results.clone(),
        bit_autodiff_results: bit_autodiff_results.clone(),
        bit_dp_autodiff_results: bit_dp_autodiff_results.clone(),
        analysis: analysis.clone(),
    };
    
    // 5. ê²°ê³¼ ì¶œë ¥
    ê²°ê³¼_ìƒì„¸_ì¶œë ¥(&comprehensive_results);
    
    // 6. ì„±ëŠ¥ ê²€ì¦
    ì„±ëŠ¥_ì–´ì„¤ì…˜_ê²€ì¦(&comprehensive_results);
    
    println!("âœ… ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ");
}

fn ìˆ˜ë™_ìµœì í™”_ë²¤ì¹˜ë§ˆí¬(test_data: &[(Packed128, Vec<f32>, Vec<f32>)], iterations: usize) -> OptimizationResults {
    let start_time = Instant::now();
    let mut total_loss = 0.0;
    let mut convergence_count = 0;
    let mut stability_sum = 0.0;
    
    let mut optimizer = HybridOptimizer::new(0.01, 10);
    
    for iter in 0..iterations {
        for (i, (mut packed, target, predicted)) in test_data.iter().cloned().enumerate() {
            let loss = optimizer.step(&mut packed, &target, &predicted, 64, 64);
            total_loss += loss;
            
            // ìˆ˜ë ´ ì²´í¬
            if loss < 0.01 {
                convergence_count += 1;
            }
            
            // ìˆ˜ì¹˜ì  ì•ˆì •ì„± ì²´í¬
            if loss.is_finite() && loss >= 0.0 {
                stability_sum += 1.0;
            }
            
            if i % 10 == 0 {
                print!(".");
            }
        }
        println!(" ë°˜ë³µ {}/{} ì™„ë£Œ", iter + 1, iterations);
    }
    
    let elapsed = start_time.elapsed();
    let total_operations = test_data.len() * iterations;
    
    OptimizationResults {
        total_time_us: elapsed.as_micros() as f64,
        average_loss: total_loss / total_operations as f32,
        memory_usage_bytes: std::mem::size_of::<HybridOptimizer>(),
        throughput_ips: total_operations as f64 / elapsed.as_secs_f64(),
        convergence_rate: convergence_count as f64 / total_operations as f64,
        numerical_stability: stability_sum / total_operations as f32,
    }
}

fn f32_ìë™ë¯¸ë¶„_ë²¤ì¹˜ë§ˆí¬(test_data: &[(Packed128, Vec<f32>, Vec<f32>)], iterations: usize) -> OptimizationResults {
    let start_time = Instant::now();
    let mut total_loss = 0.0;
    let mut convergence_count = 0;
    let mut stability_sum = 0.0;
    
    let mut computation_graph = ComputationGraph::new();
    
    for iter in 0..iterations {
        for (i, (packed, target, predicted)) in test_data.iter().enumerate() {
            // f32 ê¸°ë°˜ ìë™ë¯¸ë¶„ (ê¸°ì¡´ ë°©ì‹)
            let input_tensor = RBETensor::new(
                vec![*packed],
                vec![1, 64, 64],
                true,
            );
            
            let input_id = computation_graph.register_tensor(input_tensor);
            
            // ì—°ì‚° ê·¸ë˜í”„ êµ¬ì„± (ì˜¤ë²„í—¤ë“œ ë°œìƒ)
            let _matmul_node = computation_graph.add_node(
                RBEOperation::PackedMatMul {
                    input: input_id,
                    weight: input_id, // ê°„ë‹¨í™”
                },
                vec![1, 64, 64],
            );
            
            // ì˜¬ë°”ë¥¸ MSE ì†ì‹¤ ê³„ì‚°
            let loss = predicted.iter().zip(target.iter())
                .map(|(p, t)| (p - t).powi(2))
                .sum::<f32>() / predicted.len() as f32;
            
            total_loss += loss;
            
            if loss < 0.01 {
                convergence_count += 1;
            }
            
            if loss.is_finite() && loss >= 0.0 {
                stability_sum += 1.0;
            }
            
            if i % 10 == 0 {
                print!(".");
            }
        }
        println!(" ë°˜ë³µ {}/{} ì™„ë£Œ", iter + 1, iterations);
    }
    
    let elapsed = start_time.elapsed();
    let total_operations = test_data.len() * iterations;
    
    OptimizationResults {
        total_time_us: elapsed.as_micros() as f64,
        average_loss: total_loss / total_operations as f32,
        memory_usage_bytes: std::mem::size_of::<ComputationGraph>() * 2, // ì¶”ì •ê°’
        throughput_ips: total_operations as f64 / elapsed.as_secs_f64(),
        convergence_rate: convergence_count as f64 / total_operations as f64,
        numerical_stability: stability_sum / total_operations as f32,
    }
}

fn ë¹„íŠ¸_ìë™ë¯¸ë¶„_ë²¤ì¹˜ë§ˆí¬(
    test_data: &[(Packed128, Vec<f32>, Vec<f32>)], 
    cycle_states: &[CycleState],
    iterations: usize
) -> OptimizationResults {
    let start_time = Instant::now();
    let mut total_loss = 0.0;
    let mut convergence_count = 0;
    let mut stability_sum = 0.0;
    
    for iter in 0..iterations {
        for (i, (mut packed, target, predicted)) in test_data.iter().cloned().enumerate() {
            // ğŸš€ ë¹„íŠ¸ ë„¤ì´í‹°ë¸Œ ìë™ë¯¸ë¶„ + ì‹¤ì œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
            let mut input_tensor = BitTensor::new(
                vec![packed],
                vec![1, 64, 64],
                true,
            );
            
            let mut weight_tensor = BitTensor::new(
                vec![packed], // ê°„ë‹¨í™”ë¥¼ ìœ„í•´ ë™ì¼ ì‚¬ìš©
                vec![64, 64],
                true,
            );
            
            // 128ë¹„íŠ¸ ìœµí•© MatMul (ë‹¨ì¼ ì—°ì‚°)
            let result = input_tensor.fused_matmul_128(&weight_tensor);
            
            // 11ë¹„íŠ¸ ì‚¬ì´í´ ì „ì´
            let cycle_result = result.cycle_transition_11bit(cycle_states);
            
            // í‘¸ì•µì¹´ë ˆ ë³¼ ì—…ë°ì´íŠ¸
            let final_result = cycle_result.poincare_update(0.1, 0.01);
            
            // ì˜¬ë°”ë¥¸ MSE ì†ì‹¤ ê³„ì‚° (ë¹„íŠ¸ì—ì„œ ì§ì ‘)
            let bit_outputs: Vec<f32> = final_result.data.iter()
                .map(|p| f32::from_bits(p.lo as u32))
                .collect();
            
            let loss = if bit_outputs.len() == target.len() {
                bit_outputs.iter().zip(target.iter())
                    .map(|(b, t)| (b - t).powi(2))
                    .sum::<f32>() / target.len() as f32
            } else {
                // í¬ê¸°ê°€ ë‹¤ë¥¼ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œë§Œ ë¹„êµ
                let bit_out = bit_outputs.get(0).unwrap_or(&0.0);
                let target_avg = target.iter().sum::<f32>() / target.len() as f32;
                (bit_out - target_avg).powi(2)
            };
            
            // ğŸ¯ ì—­ì „íŒŒ ìˆ˜í–‰ - ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
            let grad_magnitude = final_result.bit_gradients.gradient_magnitude();
            
            // ğŸ¯ ì‹¤ì œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ (ë¹„íŠ¸ ìˆ˜ì¤€)
            if grad_magnitude > 0.0001 { // ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì¶©ë¶„íˆ í´ ë•Œë§Œ ì—…ë°ì´íŠ¸
                let learning_rate = 0.01;
                
                // ë¹„íŠ¸ ìë™ë¯¸ë¶„ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
                for (bit_idx, grad_array) in final_result.bit_gradients.bit_grads.iter().enumerate() {
                    if bit_idx < input_tensor.data.len() {
                        let mut data = &mut input_tensor.data[bit_idx];
                        
                        // Hi í•„ë“œ ì—…ë°ì´íŠ¸ (ì´ì‚° ë¹„íŠ¸)
                        for bit_pos in 0..64 {
                            let grad_val = grad_array[bit_pos];
                            if grad_val.abs() > 0.01 {
                                // ê·¸ë˜ë””ì–¸íŠ¸ ë°©í–¥ì— ë”°ë¥¸ ë¹„íŠ¸ í”Œë¦½
                                if grad_val > 0.0 {
                                    data.hi |= 1 << bit_pos; // ë¹„íŠ¸ ì„¤ì •
                                } else {
                                    data.hi &= !(1 << bit_pos); // ë¹„íŠ¸ í•´ì œ
                                }
                            }
                        }
                        
                        // Lo í•„ë“œ ì—…ë°ì´íŠ¸ (ì—°ì† íŒŒë¼ë¯¸í„°)
                        let r_grad = grad_array[64];
                        let theta_grad = grad_array[65];
                        
                        let current_r = f32::from_bits(data.lo as u32);
                        let current_theta = f32::from_bits((data.lo >> 32) as u32);
                        
                        let new_r = (current_r - learning_rate * r_grad).max(0.001).min(0.999);
                        let new_theta = current_theta - learning_rate * theta_grad;
                        
                        data.lo = ((new_theta.to_bits() as u64) << 32) | (new_r.to_bits() as u64);
                    }
                }
            }
            
            total_loss += loss;
            
            if loss < 0.01 {
                convergence_count += 1;
            }
            
            if loss.is_finite() && loss >= 0.0 {
                stability_sum += 1.0;
            }
            
            if i % 10 == 0 {
                print!(".");
            }
        }
        println!(" ë°˜ë³µ {}/{} ì™„ë£Œ", iter + 1, iterations);
    }
    
    let elapsed = start_time.elapsed();
    let total_operations = test_data.len() * iterations;
    
    OptimizationResults {
        total_time_us: elapsed.as_micros() as f64,
        average_loss: total_loss / total_operations as f32,
        memory_usage_bytes: std::mem::size_of::<BitTensor>(),
        throughput_ips: total_operations as f64 / elapsed.as_secs_f64(),
        convergence_rate: convergence_count as f64 / total_operations as f64,
        numerical_stability: stability_sum / total_operations as f32,
    }
}

fn ë¹„íŠ¸_DP_ìë™ë¯¸ë¶„_ë²¤ì¹˜ë§ˆí¬(
    test_data: &[(Packed128, Vec<f32>, Vec<f32>)], 
    cycle_states: &[CycleState],
    iterations: usize
) -> OptimizationResults {
    let start_time = Instant::now();
    let mut total_loss = 0.0;
    let mut convergence_count = 0;
    let mut stability_sum = 0.0;
    let mut total_cache_hits = 0;
    let mut total_cache_misses = 0;
    
    for iter in 0..iterations {
        for (i, (mut packed, target, predicted)) in test_data.iter().cloned().enumerate() {
            // ğŸš€ ë¹„íŠ¸ DP ë„¤ì´í‹°ë¸Œ ìë™ë¯¸ë¶„ + ë©”ëª¨ì´ì œì´ì…˜
            let mut input_tensor = BitDPTensor::new(
                vec![packed],
                vec![1, 64, 64],
                true,
            );
            
            let mut weight_tensor = BitDPTensor::new(
                vec![packed], // ê°„ë‹¨í™”ë¥¼ ìœ„í•´ ë™ì¼ ì‚¬ìš©
                vec![64, 64],
                true,
            );
            
            // ğŸ§® DP ê¸°ë°˜ 128ë¹„íŠ¸ ìœµí•© MatMul (ë©”ëª¨ì´ì œì´ì…˜)
            let mut result = input_tensor.dp_matmul(&mut weight_tensor);
            
            // ğŸ§® DP ê¸°ë°˜ 11ë¹„íŠ¸ ì‚¬ì´í´ ì „ì´
            let mut cycle_result = result.dp_state_transition(cycle_states);
            
            // ğŸ§® DP ê¸°ë°˜ í‘¸ì•µì¹´ë ˆ ë³¼ ì—…ë°ì´íŠ¸
            let final_result = cycle_result.dp_poincare_update(0.1, 0.01);
            
            // ì˜¬ë°”ë¥¸ MSE ì†ì‹¤ ê³„ì‚° (DP ê²°ê³¼ ê¸°ë°˜)
            let dp_outputs: Vec<f32> = final_result.data.iter()
                .map(|p| f32::from_bits(p.lo as u32))
                .collect();
            
            let loss = if dp_outputs.len() == target.len() {
                dp_outputs.iter().zip(target.iter())
                    .map(|(b, t)| (b - t).powi(2))
                    .sum::<f32>() / target.len() as f32
            } else {
                // í¬ê¸°ê°€ ë‹¤ë¥¼ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œë§Œ ë¹„êµ
                let dp_out = dp_outputs.get(0).unwrap_or(&0.0);
                let target_avg = target.iter().sum::<f32>() / target.len() as f32;
                (dp_out - target_avg).powi(2)
            };
            
            // ğŸ§® DP ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
            let gradient = input_tensor.dp_gradient_computation(loss);
            
            // ğŸ¯ ì‹¤ì œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ (DP ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜)
            if gradient.iter().any(|&g| g.abs() > 0.0001) {
                let learning_rate = 0.01;
                
                // DP ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
                for (tensor_idx, data) in input_tensor.data.iter_mut().enumerate() {
                    // Hi í•„ë“œ ì—…ë°ì´íŠ¸ (ì´ì‚° ë¹„íŠ¸)
                    for bit_pos in 0..64 {
                        let grad_val = gradient[bit_pos];
                        if grad_val.abs() > 0.01 {
                            // DP ìµœì í™”ëœ ë¹„íŠ¸ í”Œë¦½
                            if grad_val > 0.0 {
                                data.hi |= 1 << bit_pos;
                            } else {
                                data.hi &= !(1 << bit_pos);
                            }
                        }
                    }
                    
                    // Lo í•„ë“œ ì—…ë°ì´íŠ¸ (ì—°ì† íŒŒë¼ë¯¸í„°)
                    let r_grad = gradient[64];
                    let current_r = f32::from_bits(data.lo as u32);
                    let new_r = (current_r - learning_rate * r_grad).max(0.001).min(0.999);
                    data.lo = new_r.to_bits() as u64;
                }
            }
            
            // DP ìºì‹œ ì„±ëŠ¥ ì§‘ê³„
            total_cache_hits += input_tensor.dp_table.cache_hits();
            total_cache_misses += input_tensor.dp_table.cache_misses();
            
            total_loss += loss;
            
            if loss < 0.01 {
                convergence_count += 1;
            }
            
            if loss.is_finite() && loss >= 0.0 {
                stability_sum += 1.0;
            }
            
            if i % 10 == 0 {
                print!(".");
            }
        }
        println!(" ë°˜ë³µ {}/{} ì™„ë£Œ", iter + 1, iterations);
    }
    
    let elapsed = start_time.elapsed();
    let total_operations = test_data.len() * iterations;
    
    // DP ìºì‹œ ì„±ëŠ¥ ì¶œë ¥
    let cache_hit_rate = if total_cache_hits + total_cache_misses > 0 {
        total_cache_hits as f64 / (total_cache_hits + total_cache_misses) as f64 * 100.0
    } else {
        0.0
    };
    
    println!("ğŸ§® DP ìºì‹œ ì ì¤‘ë¥ : {:.1}% (íˆíŠ¸: {}, ë¯¸ìŠ¤: {})", 
             cache_hit_rate, total_cache_hits, total_cache_misses);
    
    OptimizationResults {
        total_time_us: elapsed.as_micros() as f64,
        average_loss: total_loss / total_operations as f32,
        memory_usage_bytes: std::mem::size_of::<BitDPTensor>(),
        throughput_ips: total_operations as f64 / elapsed.as_secs_f64(),
        convergence_rate: convergence_count as f64 / total_operations as f64,
        numerical_stability: stability_sum / total_operations as f32,
    }
}

fn ì„±ëŠ¥_ë¶„ì„_ìˆ˜í–‰_í™•ì¥(
    manual: &OptimizationResults,
    f32_autodiff: &OptimizationResults,
    bit_autodiff: &OptimizationResults,
    bit_dp_autodiff: &OptimizationResults,
) -> PerformanceAnalysis {
    // ê°€ì¥ ì¢‹ì€ ìë™ë¯¸ë¶„ ë°©ì‹ ì„ íƒ (ë¹„íŠ¸ DP vs ë¹„íŠ¸)
    let best_autodiff = if bit_dp_autodiff.total_time_us < bit_autodiff.total_time_us {
        bit_dp_autodiff
    } else {
        bit_autodiff
    };
    let bit_vs_manual_speedup = manual.total_time_us / best_autodiff.total_time_us;
    let bit_vs_f32_speedup = f32_autodiff.total_time_us / best_autodiff.total_time_us;
    
    let accuracy_improvement = ((manual.average_loss - best_autodiff.average_loss) 
                               / manual.average_loss * 100.0).max(0.0) as f64;
    
    let memory_efficiency = (manual.memory_usage_bytes as f64 / best_autodiff.memory_usage_bytes as f64 - 1.0) * 100.0;
    
    // ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· ) - ìµœê³  ì„±ëŠ¥ ê¸°ì¤€
    let speed_score = (bit_vs_manual_speedup.min(10.0) / 10.0 * 40.0) as f32;
    let accuracy_score = (best_autodiff.convergence_rate * 30.0) as f32;
    let stability_score = best_autodiff.numerical_stability * 20.0;
    let memory_score = (memory_efficiency.max(0.0).min(100.0) / 100.0 * 10.0) as f32;
    
    let overall_score = speed_score + accuracy_score + stability_score + memory_score;
    
    PerformanceAnalysis {
        bit_vs_manual_speedup,
        bit_vs_f32_speedup,
        accuracy_improvement_percent: accuracy_improvement,
        memory_efficiency_improvement: memory_efficiency,
        overall_performance_score: overall_score,
    }
}

fn ê²°ê³¼_ìƒì„¸_ì¶œë ¥(results: &ComprehensiveBenchmarkResults) {
    println!("\nğŸ¯ =================== ì¢…í•© ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ===================");
    
    println!("\nğŸ“Š 1. ì‹¤í–‰ ì‹œê°„ ë¹„êµ:");
    println!("   ìˆ˜ë™ ìµœì í™”:       {:.2}ms", results.manual_results.total_time_us / 1000.0);
    println!("   f32 ìë™ë¯¸ë¶„:      {:.2}ms", results.f32_autodiff_results.total_time_us / 1000.0);
    println!("   ë¹„íŠ¸ ìë™ë¯¸ë¶„:     {:.2}ms", results.bit_autodiff_results.total_time_us / 1000.0);
    println!("   ë¹„íŠ¸ DP ìë™ë¯¸ë¶„:  {:.2}ms", results.bit_dp_autodiff_results.total_time_us / 1000.0);
    
    println!("\nâš¡ 2. ì†ë„ í–¥ìƒ:");
    println!("   ë¹„íŠ¸ vs ìˆ˜ë™:   {:.2}x", results.analysis.bit_vs_manual_speedup);
    println!("   ë¹„íŠ¸ vs f32:    {:.2}x", results.analysis.bit_vs_f32_speedup);
    
    println!("\nğŸ¯ 3. ì •í™•ë„ ë¹„êµ:");
    println!("   ìˆ˜ë™ í‰ê·  ì†ì‹¤:      {:.6}", results.manual_results.average_loss);
    println!("   f32 í‰ê·  ì†ì‹¤:       {:.6}", results.f32_autodiff_results.average_loss);
    println!("   ë¹„íŠ¸ í‰ê·  ì†ì‹¤:      {:.6}", results.bit_autodiff_results.average_loss);
    println!("   ë¹„íŠ¸ DP í‰ê·  ì†ì‹¤:   {:.6}", results.bit_dp_autodiff_results.average_loss);
    println!("   ì •í™•ë„ ê°œì„ :         {:.2}%", results.analysis.accuracy_improvement_percent);
    
    println!("\nğŸ’¾ 4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±:");
    println!("   ìˆ˜ë™ ë©”ëª¨ë¦¬:         {:.2}KB", results.manual_results.memory_usage_bytes as f64 / 1024.0);
    println!("   f32 ë©”ëª¨ë¦¬:          {:.2}KB", results.f32_autodiff_results.memory_usage_bytes as f64 / 1024.0);
    println!("   ë¹„íŠ¸ ë©”ëª¨ë¦¬:         {:.2}KB", results.bit_autodiff_results.memory_usage_bytes as f64 / 1024.0);
    println!("   ë¹„íŠ¸ DP ë©”ëª¨ë¦¬:      {:.2}KB", results.bit_dp_autodiff_results.memory_usage_bytes as f64 / 1024.0);
    println!("   ë©”ëª¨ë¦¬ íš¨ìœ¨ ê°œì„ :    {:.2}%", results.analysis.memory_efficiency_improvement);
    
    println!("\nğŸš€ 5. ì²˜ë¦¬ ì†ë„ (ops/sec):");
    println!("   ìˆ˜ë™:       {:.0}", results.manual_results.throughput_ips);
    println!("   f32:        {:.0}", results.f32_autodiff_results.throughput_ips);
    println!("   ë¹„íŠ¸:       {:.0}", results.bit_autodiff_results.throughput_ips);
    println!("   ë¹„íŠ¸ DP:    {:.0}", results.bit_dp_autodiff_results.throughput_ips);
    
    println!("\nğŸ“ˆ 6. ìˆ˜ë ´ë¥ :");
    println!("   ìˆ˜ë™:       {:.2}%", results.manual_results.convergence_rate * 100.0);
    println!("   f32:        {:.2}%", results.f32_autodiff_results.convergence_rate * 100.0);
    println!("   ë¹„íŠ¸:       {:.2}%", results.bit_autodiff_results.convergence_rate * 100.0);
    println!("   ë¹„íŠ¸ DP:    {:.2}%", results.bit_dp_autodiff_results.convergence_rate * 100.0);
    
    println!("\nğŸ† 7. ì¢…í•© ì„±ëŠ¥ ì ìˆ˜: {:.1}/100", results.analysis.overall_performance_score);
    
    // ğŸ§® DP ìë™ë¯¸ë¶„ ì¶”ê°€ ë¶„ì„
    println!("\nğŸ§® 8. DP ìë™ë¯¸ë¶„ ìƒì„¸ ë¶„ì„:");
    let dp_vs_bit_speedup = results.bit_autodiff_results.total_time_us / results.bit_dp_autodiff_results.total_time_us;
    let dp_vs_manual_speedup = results.manual_results.total_time_us / results.bit_dp_autodiff_results.total_time_us;
    let dp_vs_f32_speedup = results.f32_autodiff_results.total_time_us / results.bit_dp_autodiff_results.total_time_us;
    
    println!("   DP vs ë¹„íŠ¸:    {:.2}x", dp_vs_bit_speedup);
    println!("   DP vs ìˆ˜ë™:    {:.2}x", dp_vs_manual_speedup);
    println!("   DP vs f32:     {:.2}x", dp_vs_f32_speedup);
    
    if dp_vs_bit_speedup > 1.0 && dp_vs_f32_speedup > 1.0 {
        println!("   ğŸš€ DP ì•Œê³ ë¦¬ì¦˜ì´ ëª¨ë“  ë°©ë²•ë³´ë‹¤ ë¹ ë¦„!");
    } else if dp_vs_bit_speedup > 1.0 {
        println!("   ğŸš€ DP ì•Œê³ ë¦¬ì¦˜ì´ ê¸°ë³¸ ë¹„íŠ¸ ìë™ë¯¸ë¶„ë³´ë‹¤ ë¹ ë¦„!");
    }
    
    println!("\nğŸ–ï¸  ============== ìµœì¢… ì„±ëŠ¥ ë“±ê¸‰ ==============");
    let grade = match results.analysis.overall_performance_score {
        90.0..=100.0 => "Sê¸‰ (íƒì›”)",
        80.0..=89.9 => "Aê¸‰ (ìš°ìˆ˜)",
        70.0..=79.9 => "Bê¸‰ (ì–‘í˜¸)",
        60.0..=69.9 => "Cê¸‰ (ë³´í†µ)",
        _ => "Dê¸‰ (ê°œì„  í•„ìš”)",
    };
    println!("   ë¹„íŠ¸ ìë™ë¯¸ë¶„ ì„±ëŠ¥ ë“±ê¸‰: {}", grade);
}

fn ì„±ëŠ¥_ì–´ì„¤ì…˜_ê²€ì¦(results: &ComprehensiveBenchmarkResults) {
    // 1. ë¹„íŠ¸ ìë™ë¯¸ë¶„ì´ f32 ìë™ë¯¸ë¶„ë³´ë‹¤ ë¹¨ë¼ì•¼ í•¨
    assert!(
        results.analysis.bit_vs_f32_speedup > 1.0,
        "ë¹„íŠ¸ ìë™ë¯¸ë¶„ì´ f32 ìë™ë¯¸ë¶„ë³´ë‹¤ ëŠë¦¼: {:.2}x",
        results.analysis.bit_vs_f32_speedup
    );
    
    // 2. ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì´ 90% ì´ìƒì´ì–´ì•¼ í•¨
    assert!(
        results.bit_autodiff_results.numerical_stability > 0.9,
        "ë¹„íŠ¸ ìë™ë¯¸ë¶„ ìˆ˜ì¹˜ì  ì•ˆì •ì„± ë¶€ì¡±: {:.2}%",
        results.bit_autodiff_results.numerical_stability * 100.0
    );
    
    // 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í•©ë¦¬ì ì´ì–´ì•¼ í•¨ (1MB ì´í•˜)
    assert!(
        results.bit_autodiff_results.memory_usage_bytes < 1024 * 1024,
        "ë¹„íŠ¸ ìë™ë¯¸ë¶„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³¼ë‹¤: {}MB",
        results.bit_autodiff_results.memory_usage_bytes / (1024 * 1024)
    );
    
    // 4. ì²˜ë¦¬ ì†ë„ê°€ ìµœì†Œ 10 ops/sec ì´ìƒì´ì–´ì•¼ í•¨
    assert!(
        results.bit_autodiff_results.throughput_ips > 10.0,
        "ë¹„íŠ¸ ìë™ë¯¸ë¶„ ì²˜ë¦¬ ì†ë„ ë¶€ì¡±: {:.0} ops/sec",
        results.bit_autodiff_results.throughput_ips
    );
    
    // 5. ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ê°€ 70ì  ì´ìƒì´ì–´ì•¼ í•¨
    assert!(
        results.analysis.overall_performance_score > 70.0,
        "ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ ë¶€ì¡±: {:.1}/100",
        results.analysis.overall_performance_score
    );
} 