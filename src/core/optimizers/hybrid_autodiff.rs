use crate::core::{
    packed_params::packed_types::Packed128,
    optimizers::{
        hybrid::HybridOptimizer,
        auto_diff::{RBEGradient, RBETensor, ComputationGraph, RBEOperation},
        cycle_differential::CycleState,
    },
};
use anyhow::Result;
use std::time::Instant;

/// ìë™ë¯¸ë¶„ í†µí•© í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™”ê¸°
#[derive(Debug)]
pub struct AutoDiffHybridOptimizer {
    /// ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™”ê¸°
    base_optimizer: HybridOptimizer,
    /// ì—°ì‚° ê·¸ë˜í”„
    computation_graph: ComputationGraph,
    /// ì„±ëŠ¥ ë©”íŠ¸ë¦­
    performance_metrics: AutoDiffPerformanceMetrics,
    /// ìë™ë¯¸ë¶„ í™œì„±í™” ì—¬ë¶€
    autodiff_enabled: bool,
}

/// ìë™ë¯¸ë¶„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
#[derive(Debug, Clone)]
pub struct AutoDiffPerformanceMetrics {
    /// ìˆœì „íŒŒ ì‹œê°„ (ë§ˆì´í¬ë¡œì´ˆ)
    pub forward_time_us: f64,
    /// ì—­ì „íŒŒ ì‹œê°„ (ë§ˆì´í¬ë¡œì´ˆ)
    pub backward_time_us: f64,
    /// ì´ ìµœì í™” ì‹œê°„ (ë§ˆì´í¬ë¡œì´ˆ)
    pub total_optimization_time_us: f64,
    /// ê¸°ì¡´ ëŒ€ë¹„ ì†ë„ í–¥ìƒ ë°°ìˆ˜
    pub speedup_factor: f64,
    /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë°”ì´íŠ¸)
    pub memory_usage_bytes: usize,
    /// ì •í™•ë„ ê°œì„ ë¥  (%)
    pub accuracy_improvement_percent: f64,
    /// ì‹¤í–‰ ìŠ¤í… ìˆ˜
    pub executed_steps: usize,
}

impl AutoDiffPerformanceMetrics {
    pub fn new() -> Self {
        Self {
            forward_time_us: 0.0,
            backward_time_us: 0.0,
            total_optimization_time_us: 0.0,
            speedup_factor: 1.0,
            memory_usage_bytes: 0,
            accuracy_improvement_percent: 0.0,
            executed_steps: 0,
        }
    }
}

impl AutoDiffHybridOptimizer {
    /// ìƒˆë¡œìš´ ìë™ë¯¸ë¶„ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™”ê¸° ìƒì„±
    pub fn new(learning_rate: f32, max_cycle_length: usize, autodiff_enabled: bool) -> Self {
        Self {
            base_optimizer: HybridOptimizer::new(learning_rate, max_cycle_length),
            computation_graph: ComputationGraph::new(),
            performance_metrics: AutoDiffPerformanceMetrics::new(),
            autodiff_enabled,
        }
    }
    
    /// ìë™ë¯¸ë¶„ì„ í™œìš©í•œ ìµœì í™” ìŠ¤í…
    pub fn step_with_autodiff(
        &mut self,
        packed: &mut Packed128,
        target: &[f32],
        predicted: &[f32],
        rows: usize,
        cols: usize,
    ) -> Result<f32> {
        let start_time = Instant::now();
        
        if self.autodiff_enabled {
            self.autodiff_step(packed, target, predicted, rows, cols)
        } else {
            self.manual_step(packed, target, predicted, rows, cols)
        }
        .map(|loss| {
            self.performance_metrics.total_optimization_time_us += 
                start_time.elapsed().as_micros() as f64;
            self.performance_metrics.executed_steps += 1;
            loss
        })
    }
    
    /// ìë™ë¯¸ë¶„ ê¸°ë°˜ ìµœì í™” ìŠ¤í…
    fn autodiff_step(
        &mut self,
        packed: &mut Packed128,
        target: &[f32],
        predicted: &[f32],
        rows: usize,
        cols: usize,
    ) -> Result<f32> {
        // 1. RBETensor ìƒì„±
        let input_tensor = RBETensor::new(
            vec![*packed],
            vec![1, rows, cols],
            true, // requires_grad = true
        );
        
        // 2. ì—°ì‚° ê·¸ë˜í”„ êµ¬ì„±
        let input_id = self.computation_graph.register_tensor(input_tensor);
        
        // 3. ìˆœì „íŒŒ ì—°ì‚°ë“¤ ì¶”ê°€
        let forward_start = Instant::now();
        
        // 3.1. 11ë¹„íŠ¸ ì‚¬ì´í´ ì „ì´ ì¶”ê°€
        let cycle_states = self.generate_cycle_states(rows * cols);
        let cycle_node = self.computation_graph.add_node(
            RBEOperation::CycleTransition {
                input: input_id,
                cycle_params: cycle_states,
            },
            vec![1, rows, cols],
        );
        
        // 3.2. í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” ì¶”ê°€
        let hybrid_node = self.computation_graph.add_node(
            RBEOperation::HybridOptimize {
                input: cycle_node,
                target: target.to_vec(),
            },
            vec![1, rows, cols],
        );
        
        // 3.3. ë¦¬ë§Œ ê¸°í•˜í•™ì  ì—…ë°ì´íŠ¸ ì¶”ê°€
        let riemannian_node = self.computation_graph.add_node(
            RBEOperation::RiemannianUpdate {
                input: hybrid_node,
                manifold_params: (0.1, 0.01), // ê³¡ë¥ ê³¼ ë©”íŠ¸ë¦­ ìŠ¤ì¼€ì¼
            },
            vec![1, rows, cols],
        );
        
        // 4. ìˆœì „íŒŒ ì‹¤í–‰
        let output = self.computation_graph.forward(input_id)?;
        
        self.performance_metrics.forward_time_us += 
            forward_start.elapsed().as_micros() as f64;
        
        // 5. ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°
        let loss = self.compute_loss(&output, target);
        
        // 6. ì—­ì „íŒŒ ì‹¤í–‰
        let backward_start = Instant::now();
        
        let loss_gradient = self.compute_loss_gradient(&output, target);
        self.computation_graph.backward(&loss_gradient)?;
        
        self.performance_metrics.backward_time_us += 
            backward_start.elapsed().as_micros() as f64;
        
        // 7. íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        if !output.data.is_empty() {
            *packed = output.data[0];
        }
        
        // 8. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
        self.update_memory_usage();
        
        Ok(loss)
    }
    
    /// ê¸°ì¡´ ìˆ˜ë™ ìµœì í™” ìŠ¤í… (ë¹„êµìš©)
    fn manual_step(
        &mut self,
        packed: &mut Packed128,
        target: &[f32],
        predicted: &[f32],
        rows: usize,
        cols: usize,
    ) -> Result<f32> {
        // ê¸°ì¡´ HybridOptimizer ì‚¬ìš©
        Ok(self.base_optimizer.step(packed, target, predicted, rows, cols))
    }
    
    /// ì‚¬ì´í´ ìƒíƒœ ìƒì„± (11ë¹„íŠ¸ êµ¬ì¡°)
    fn generate_cycle_states(&self, count: usize) -> Vec<CycleState> {
        (0..count)
            .map(|i| {
                let bits = (i % 2048) as u16; // 11ë¹„íŠ¸ ë²”ìœ„
                CycleState::from_bits(bits)
            })
            .collect()
    }
    
    /// ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚° (MSE)
    fn compute_loss(&self, output: &RBETensor, target: &[f32]) -> f32 {
        let mut total_loss = 0.0;
        let mut count = 0;
        
        for (i, packed_data) in output.data.iter().enumerate() {
            if i < target.len() {
                // Lo í•„ë“œì—ì„œ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
                let predicted = f32::from_bits(packed_data.lo as u32);
                let error = target[i] - predicted;
                total_loss += error * error;
                count += 1;
            }
        }
        
        if count > 0 {
            total_loss / count as f32
        } else {
            0.0
        }
    }
    
    /// ì†ì‹¤ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
    fn compute_loss_gradient(&self, output: &RBETensor, target: &[f32]) -> RBEGradient {
        let mut gradient = RBEGradient::new();
        
        for (i, packed_data) in output.data.iter().enumerate() {
            if i < target.len() && i < gradient.hi_gradients.len() {
                // Lo í•„ë“œì—ì„œ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
                let predicted = f32::from_bits(packed_data.lo as u32);
                let error = target[i] - predicted;
                
                // MSE ê·¸ë˜ë””ì–¸íŠ¸: 2 * (predicted - target) / N
                let grad_value = 2.0 * error / target.len() as f32;
                
                // Hi í•„ë“œ ê·¸ë˜ë””ì–¸íŠ¸ (ì´ì‚°)
                gradient.hi_gradients[i] = if error.abs() > 0.1 { grad_value } else { 0.0 };
                
                // Lo í•„ë“œ ê·¸ë˜ë””ì–¸íŠ¸ (ì—°ì†)
                if i == 0 {
                    gradient.lo_gradients.0 = grad_value; // r ì„±ë¶„
                }
                if i == 1 {
                    gradient.lo_gradients.1 = grad_value; // theta ì„±ë¶„
                }
            }
        }
        
        gradient.compute_magnitude();
        gradient
    }
    
    /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
    fn update_memory_usage(&mut self) {
        // ì—°ì‚° ê·¸ë˜í”„ì™€ í…ì„œë“¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
        let tensor_memory = std::mem::size_of::<RBETensor>() * 10; // ì¶”ì •ê°’
        let graph_memory = std::mem::size_of::<ComputationGraph>();
        let gradient_memory = std::mem::size_of::<RBEGradient>() * 5; // ì¶”ì •ê°’
        
        self.performance_metrics.memory_usage_bytes = 
            tensor_memory + graph_memory + gradient_memory;
    }
    
    /// ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜
    pub fn get_performance_metrics(&self) -> &AutoDiffPerformanceMetrics {
        &self.performance_metrics
    }
    
    /// ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰ (ìë™ë¯¸ë¶„ vs ìˆ˜ë™)
    pub fn benchmark_comparison(
        &mut self,
        test_data: &[(Packed128, Vec<f32>, Vec<f32>)], // (packed, target, predicted)
        iterations: usize,
    ) -> Result<BenchmarkResults> {
        let mut autodiff_results = Vec::new();
        let mut manual_results = Vec::new();
        
        println!("ğŸš€ ìë™ë¯¸ë¶„ vs ìˆ˜ë™ ìµœì í™” ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ({}íšŒ ë°˜ë³µ)", iterations);
        
        // ìë™ë¯¸ë¶„ í…ŒìŠ¤íŠ¸
        println!("ğŸ“Š ìë™ë¯¸ë¶„ ìµœì í™” í…ŒìŠ¤íŠ¸...");
        self.autodiff_enabled = true;
        let autodiff_start = Instant::now();
        
        for (i, (mut packed, target, predicted)) in test_data.iter().cloned().enumerate() {
            for _ in 0..iterations {
                let loss = self.step_with_autodiff(
                    &mut packed,
                    &target,
                    &predicted,
                    8, 8 // 8x8 í–‰ë ¬ ê°€ì •
                )?;
                autodiff_results.push(loss);
            }
            
            if i % 10 == 0 {
                println!("   ì§„í–‰ë¥ : {}/{}", i + 1, test_data.len());
            }
        }
        
        let autodiff_total_time = autodiff_start.elapsed();
        
        // ìˆ˜ë™ ìµœì í™” í…ŒìŠ¤íŠ¸
        println!("ğŸ“Š ìˆ˜ë™ ìµœì í™” í…ŒìŠ¤íŠ¸...");
        self.autodiff_enabled = false;
        let manual_start = Instant::now();
        
        for (i, (mut packed, target, predicted)) in test_data.iter().cloned().enumerate() {
            for _ in 0..iterations {
                let loss = self.step_with_autodiff(
                    &mut packed,
                    &target,
                    &predicted,
                    8, 8
                )?;
                manual_results.push(loss);
            }
            
            if i % 10 == 0 {
                println!("   ì§„í–‰ë¥ : {}/{}", i + 1, test_data.len());
            }
        }
        
        let manual_total_time = manual_start.elapsed();
        
        // ê²°ê³¼ ë¶„ì„
        let autodiff_avg_loss = autodiff_results.iter().sum::<f32>() / autodiff_results.len() as f32;
        let manual_avg_loss = manual_results.iter().sum::<f32>() / manual_results.len() as f32;
        
        let speedup = manual_total_time.as_micros() as f64 / autodiff_total_time.as_micros() as f64;
        let accuracy_improvement = ((manual_avg_loss - autodiff_avg_loss) / manual_avg_loss * 100.0).max(0.0);
        
        // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.performance_metrics.speedup_factor = speedup;
        self.performance_metrics.accuracy_improvement_percent = accuracy_improvement as f64;
        
        Ok(BenchmarkResults {
            autodiff_time_ms: autodiff_total_time.as_millis() as f64,
            manual_time_ms: manual_total_time.as_millis() as f64,
            autodiff_avg_loss,
            manual_avg_loss,
            speedup_factor: speedup,
            accuracy_improvement_percent: accuracy_improvement as f64,
            iterations_per_second_autodiff: (test_data.len() * iterations) as f64 / autodiff_total_time.as_secs_f64(),
            iterations_per_second_manual: (test_data.len() * iterations) as f64 / manual_total_time.as_secs_f64(),
        })
    }
    
    /// ì •í™•ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸
    pub fn validate_accuracy(
        &mut self,
        test_cases: &[(Vec<f32>, Vec<f32>)], // (input, expected_output)
    ) -> Result<AccuracyResults> {
        let mut total_error = 0.0;
        let mut max_error: f32 = 0.0;
        let mut converged_cases = 0;
        
        self.autodiff_enabled = true;
        
        for (i, (input, expected)) in test_cases.iter().enumerate() {
            let mut packed = Packed128 {
                hi: 0x123456789ABCDEF0,
                lo: input.get(0).unwrap_or(&0.0).to_bits() as u64,
            };
            
            // ì—¬ëŸ¬ ìŠ¤í…ìœ¼ë¡œ ìˆ˜ë ´ í…ŒìŠ¤íŠ¸
            let mut final_loss = f32::INFINITY;
            for step in 0..100 {
                let predicted = vec![f32::from_bits(packed.lo as u32)];
                final_loss = self.step_with_autodiff(
                    &mut packed,
                    expected,
                    &predicted,
                    1, 1
                )?;
                
                // ìˆ˜ë ´ ì²´í¬
                if final_loss < 1e-6 {
                    converged_cases += 1;
                    break;
                }
            }
            
            total_error += final_loss;
            max_error = max_error.max(final_loss);
            
            if i % 50 == 0 {
                println!("   ì •í™•ë„ ê²€ì¦: {}/{} (í˜„ì¬ ì˜¤ì°¨: {:.6})", i + 1, test_cases.len(), final_loss);
            }
        }
        
        Ok(AccuracyResults {
            average_error: total_error / test_cases.len() as f32,
            max_error,
            convergence_rate: converged_cases as f64 / test_cases.len() as f64,
            total_test_cases: test_cases.len(),
        })
    }
    
    /// ì§„ë‹¨ ì •ë³´ ì¶œë ¥
    pub fn print_diagnostics(&self) {
        println!("\nğŸ” ìë™ë¯¸ë¶„ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™”ê¸° ì§„ë‹¨ ì •ë³´:");
        println!("   ìë™ë¯¸ë¶„ í™œì„±í™”: {}", self.autodiff_enabled);
        println!("   ìˆœì „íŒŒ í‰ê·  ì‹œê°„: {:.2}Î¼s", self.performance_metrics.forward_time_us / self.performance_metrics.executed_steps as f64);
        println!("   ì—­ì „íŒŒ í‰ê·  ì‹œê°„: {:.2}Î¼s", self.performance_metrics.backward_time_us / self.performance_metrics.executed_steps as f64);
        println!("   ì´ ìµœì í™” ì‹œê°„: {:.2}ms", self.performance_metrics.total_optimization_time_us / 1000.0);
        println!("   ì†ë„ í–¥ìƒ: {:.2}x", self.performance_metrics.speedup_factor);
        println!("   ì •í™•ë„ ê°œì„ : {:.2}%", self.performance_metrics.accuracy_improvement_percent);
        println!("   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {:.2}KB", self.performance_metrics.memory_usage_bytes as f64 / 1024.0);
        println!("   ì‹¤í–‰ ìŠ¤í… ìˆ˜: {}", self.performance_metrics.executed_steps);
    }
}

/// ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
#[derive(Debug, Clone)]
pub struct BenchmarkResults {
    pub autodiff_time_ms: f64,
    pub manual_time_ms: f64,
    pub autodiff_avg_loss: f32,
    pub manual_avg_loss: f32,
    pub speedup_factor: f64,
    pub accuracy_improvement_percent: f64,
    pub iterations_per_second_autodiff: f64,
    pub iterations_per_second_manual: f64,
}

/// ì •í™•ë„ ê²°ê³¼
#[derive(Debug, Clone)]
pub struct AccuracyResults {
    pub average_error: f32,
    pub max_error: f32,
    pub convergence_rate: f64,
    pub total_test_cases: usize,
} 