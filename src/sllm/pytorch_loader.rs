use std::path::Path;
use std::collections::HashMap;
use anyhow::{Result, anyhow};
use serde_json::Value;
use numpy::{PyArray2, PyReadonlyArray2};
use pyo3::prelude::*;
use pyo3::types::{PyDict, PyList};

/// PyTorch ëª¨ë¸ ë¡œë”
pub struct PyTorchLoader {
    python_env: Python<'static>,
}

impl PyTorchLoader {
    /// ìƒˆë¡œìš´ PyTorch ë¡œë” ìƒì„±
    pub fn new() -> Result<Self> {
        // Python ì´ˆê¸°í™”ë¥¼ ê°„ë‹¨í•˜ê²Œ ì²˜ë¦¬
        Ok(Self {
            python_env: unsafe { std::mem::transmute(0 as *const ()) },
        })
    }
    
    /// PyTorch ëª¨ë¸ì„ í…ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œ
    pub fn load_model_weights(&self, model_path: &Path) -> Result<HashMap<String, Vec<f32>>> {
        Python::with_gil(|py| {
            let model_file = model_path.join("pytorch_model.bin");
            if !model_file.exists() {
                return Err(anyhow!("pytorch_model.bin íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {:?}", model_file));
            }
            
            println!("ğŸ”„ PyTorch ëª¨ë¸ ë¡œë”© ì¤‘: {:?}", model_file);
            
            // PyTorchë¡œ ëª¨ë¸ ë¡œë“œ
            let code = format!(r#"
import torch
import numpy as np

# ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
state_dict = torch.load(r"{}", map_location='cpu')
weights = {{}}

for name, tensor in state_dict.items():
    if tensor.dim() == 2:  # 2D í…ì„œë§Œ (Linear layers)
        numpy_tensor = tensor.detach().numpy().astype(np.float32)
        weights[name] = numpy_tensor

print(f"ë¡œë“œëœ 2D ë ˆì´ì–´ ìˆ˜: {{len(weights)}}")
for name, weight in weights.items():
    print(f"  {{name}}: {{weight.shape}}")
"#, model_file.display());
            
            let locals = PyDict::new(py);
            py.run(&code, None, Some(locals))?;
            
            // Pythonì—ì„œ ê²°ê³¼ ì¶”ì¶œ
            let weights_dict: &PyDict = locals.get_item("weights").unwrap().downcast()?;
            let mut rust_weights = HashMap::new();
            
            for (name, tensor) in weights_dict.iter() {
                let name_str: String = name.extract()?;
                let numpy_array: PyReadonlyArray2<f32> = tensor.extract()?;
                let array = numpy_array.as_array();
                
                // 2D ë°°ì—´ì„ 1D ë²¡í„°ë¡œ ë³€í™˜ (row-major order)
                let flat_data: Vec<f32> = array.iter().cloned().collect();
                rust_weights.insert(name_str, flat_data);
            }
            
            println!("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {} ë ˆì´ì–´", rust_weights.len());
            Ok(rust_weights)
        })
    }
    
    /// ëª¨ë¸ ì„¤ì • ë¡œë“œ
    pub fn load_model_config(&self, model_path: &Path) -> Result<ModelConfig> {
        let config_file = model_path.join("config.json");
        let config_content = std::fs::read_to_string(config_file)?;
        let config_json: Value = serde_json::from_str(&config_content)?;
        
        Ok(ModelConfig {
            vocab_size: config_json["vocab_size"].as_u64().unwrap_or(50257) as usize,
            hidden_size: config_json["n_embd"].as_u64().unwrap_or(768) as usize,
            num_layers: config_json["n_layer"].as_u64().unwrap_or(12) as usize,
            num_heads: config_json["n_head"].as_u64().unwrap_or(12) as usize,
            max_length: config_json["n_positions"].as_u64().unwrap_or(1024) as usize,
        })
    }
}

/// ëª¨ë¸ ì„¤ì • êµ¬ì¡°ì²´
#[derive(Debug, Clone)]
pub struct ModelConfig {
    pub vocab_size: usize,
    pub hidden_size: usize,
    pub num_layers: usize,
    pub num_heads: usize,
    pub max_length: usize,
}

/// í† í¬ë‚˜ì´ì € ë˜í¼
pub struct Tokenizer {
    python_tokenizer: Py<PyAny>,
}

impl Tokenizer {
    /// í† í¬ë‚˜ì´ì € ë¡œë“œ
    pub fn load(model_path: &Path) -> Result<Self> {
        Python::with_gil(|py| {
            let code = format!(r#"
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(r"{}")
"#, model_path.display());
            
            let locals = PyDict::new(py);
            py.run(&code, None, Some(locals))?;
            
            let tokenizer = locals.get_item("tokenizer").unwrap().into();
            
            Ok(Self {
                python_tokenizer: tokenizer,
            })
        })
    }
    
    /// í…ìŠ¤íŠ¸ë¥¼ í† í° IDë¡œ ë³€í™˜
    pub fn encode(&self, text: &str) -> Result<Vec<i64>> {
        Python::with_gil(|py| {
            let tokenizer = self.python_tokenizer.as_ref(py);
            let encoded = tokenizer.call_method1("encode", (text,))?;
            let token_ids: Vec<i64> = encoded.extract()?;
            Ok(token_ids)
        })
    }
    
    /// í† í° IDë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    pub fn decode(&self, token_ids: &[i64]) -> Result<String> {
        Python::with_gil(|py| {
            let tokenizer = self.python_tokenizer.as_ref(py);
            let decoded = tokenizer.call_method1("decode", (token_ids,))?;
            let text: String = decoded.extract()?;
            Ok(text)
        })
    }
} 