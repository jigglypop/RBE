use clap::{Arg, Command};
use anyhow::{Context, Result};
use std::path::Path;
use std::fs::{self, File};
use std::io::Write;
use std::time::Instant;

use rbe_llm::core::encoder::{RBEEncoder, WeightMapper, ModelLayout, WeightInfo};
use rbe_llm::core::packed_params::{TransformType, HybridEncodedBlock};

/// GPT-2 ëª¨ë¸ ì••ì¶•ìš© ì„¤ì •
struct CompressionSettings {
    block_size: usize,
    coefficients: usize,
    transform_type: TransformType,
}

impl Default for CompressionSettings {
    fn default() -> Self {
        Self {
            block_size: 64,
            coefficients: 133,
            transform_type: TransformType::Dwt,
        }
    }
}

fn main() -> Result<()> {
    let matches = Command::new("RBE Model Compressor")
        .version("1.0")
        .author("RBE Team")
        .about("GPT-2 ëª¨ë¸ì„ RBEë¡œ ì••ì¶•í•©ë‹ˆë‹¤")
        .arg(Arg::new("input")
            .short('i')
            .long("input")
            .value_name("PATH")
            .help("ì…ë ¥ ëª¨ë¸ ë””ë ‰í† ë¦¬ (extract_weights.pyë¡œ ì¶”ì¶œí•œ í…ì„œë“¤)")
            .required(true))
        .arg(Arg::new("output")
            .short('o')
            .long("output")
            .value_name("PATH")
            .help("ì¶œë ¥ ë””ë ‰í† ë¦¬")
            .required(true))
        .arg(Arg::new("block-size")
            .short('b')
            .long("block-size")
            .value_name("SIZE")
            .help("ë¸”ë¡ í¬ê¸° (ê¸°ë³¸ê°’: 64)")
            .default_value("64"))
        .arg(Arg::new("coefficients")
            .short('c')
            .long("coefficients")
            .value_name("NUM")
            .help("ìœ ì§€í•  ê³„ìˆ˜ ê°œìˆ˜ (ê¸°ë³¸ê°’: 133)")
            .default_value("133"))
        .arg(Arg::new("transform")
            .short('t')
            .long("transform")
            .value_name("TYPE")
            .help("ë³€í™˜ íƒ€ì…: dct, dwt (ê¸°ë³¸ê°’: dwt)")
            .default_value("dwt"))
        .get_matches();
    
    let input_dir = Path::new(matches.get_one::<String>("input").unwrap());
    let output_dir = Path::new(matches.get_one::<String>("output").unwrap());
    let block_size = matches.get_one::<String>("block-size").unwrap().parse()?;
    let coefficients = matches.get_one::<String>("coefficients").unwrap().parse()?;
    let transform_type = match matches.get_one::<String>("transform").unwrap().as_str() {
        "dct" => TransformType::Dct,
        "dwt" => TransformType::Dwt,
        _ => TransformType::Dwt,
    };
    
    // ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    fs::create_dir_all(output_dir)?;

    // ì••ì¶• ì‹œì‘
    compress_gpt2_with_layout(
        input_dir,
        output_dir,
        CompressionSettings {
            block_size,
            coefficients,
            transform_type,
        }
    )?;
    
    Ok(())
}

/// GPT-2 ëª¨ë¸ì„ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì••ì¶•
fn compress_gpt2_with_layout(
    input_dir: &Path,
    output_dir: &Path,
    settings: CompressionSettings,
) -> Result<()> {
    println!("ğŸš€ GPT-2 ëª¨ë¸ ì••ì¶• ì‹œì‘");
    println!("  ì…ë ¥: {}", input_dir.display());
    println!("  ì¶œë ¥: {}", output_dir.display());
    println!("  ì„¤ì •: ë¸”ë¡={}, ê³„ìˆ˜={}, ë³€í™˜={:?}", 
        settings.block_size, settings.coefficients, settings.transform_type);
    
    let start_time = Instant::now();
    
    // 1. ê°€ì¤‘ì¹˜ ë§¤í¼ ìƒì„±
    let mut mapper = WeightMapper::new(
        "gpt2",
        settings.block_size,
        settings.coefficients,
        settings.transform_type,
    );
    
    // 2. ì••ì¶•ëœ ë¸”ë¡ë“¤ì„ ì €ì¥í•  ë²¡í„°
    let mut all_compressed_blocks = Vec::new();
    
    // 3. ëª¨ë“  í…ì„œ íŒŒì¼ ì°¾ê¸° ë° ì••ì¶•
    let tensor_files = find_tensor_files(input_dir)?;
    println!("\nğŸ“ {} ê°œì˜ í…ì„œ íŒŒì¼ ë°œê²¬", tensor_files.len());
    
    for (idx, tensor_path) in tensor_files.iter().enumerate() {
        let weight_name = tensor_path.file_stem()
            .and_then(|s| s.to_str())
            .ok_or_else(|| anyhow::anyhow!("ì˜ëª»ëœ íŒŒì¼ ì´ë¦„"))?;
        
        println!("\n[{}/{}] ì••ì¶• ì¤‘: {}", idx + 1, tensor_files.len(), weight_name);
        
        // í…ì„œ ë¡œë“œ
        let (data, shape) = load_tensor(&tensor_path)?;
        println!("  Shape: {:?}, í¬ê¸°: {:.2} MB", 
            shape, data.len() as f64 * 4.0 / 1_048_576.0);
        
        // ì••ì¶•
        let blocks = mapper.compress_weight(weight_name, &data, &shape)?;
        println!("  ì••ì¶• ì™„ë£Œ: {} ë¸”ë¡", blocks.len());
        
        all_compressed_blocks.push(blocks);
    }
    
    // 4. ëª¨ë“  ë¸”ë¡ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì§ë ¬í™”
    let bin_path = output_dir.join("rbe_model.bin");
    let bin_data = mapper.serialize_all_blocks(&all_compressed_blocks)?;
    let mut bin_file = File::create(&bin_path)?;
    bin_file.write_all(&bin_data)?;
    println!("\nâœ… ë°”ì´ë„ˆë¦¬ íŒŒì¼ ìƒì„±: {} ({:.2} MB)", 
        bin_path.display(), bin_data.len() as f64 / 1_048_576.0);
    
    // 5. ë ˆì´ì•„ì›ƒ íŒŒì¼ ì €ì¥
    let layout_path = output_dir.join("rbe_layout.json");
    let layout_json = mapper.serialize_layout()?;
    fs::write(&layout_path, layout_json)?;
    println!("âœ… ë ˆì´ì•„ì›ƒ íŒŒì¼ ìƒì„±: {}", layout_path.display());
    
    // 6. ì••ì¶• í†µê³„ ì¶œë ¥
    mapper.print_compression_stats();
    
    let elapsed = start_time.elapsed();
    println!("\nâ±ï¸  ì´ ì†Œìš” ì‹œê°„: {:.2}ì´ˆ", elapsed.as_secs_f64());
    
    Ok(())
}

/// í…ì„œ íŒŒì¼ë“¤ ì°¾ê¸°
fn find_tensor_files(dir: &Path) -> Result<Vec<std::path::PathBuf>> {
    let mut files = Vec::new();
    
    for entry in fs::read_dir(dir)? {
        let entry = entry?;
        let path = entry.path();
        
        if path.extension().and_then(|s| s.to_str()) == Some("pt") {
            files.push(path);
        }
    }
    
    // GPT-2 ë ˆì´ì–´ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    files.sort_by(|a, b| {
        let a_name = a.file_stem().unwrap().to_str().unwrap();
        let b_name = b.file_stem().unwrap().to_str().unwrap();
        
        // ë ˆì´ì–´ ë²ˆí˜¸ ì¶”ì¶œí•˜ì—¬ ì •ë ¬
        let a_layer = extract_layer_number(a_name);
        let b_layer = extract_layer_number(b_name);
        
        match (a_layer, b_layer) {
            (Some(a_n), Some(b_n)) => a_n.cmp(&b_n),
            _ => a_name.cmp(b_name),
        }
    });
    
    Ok(files)
}

/// ë ˆì´ì–´ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: "transformer.h.0.attn" -> 0)
fn extract_layer_number(name: &str) -> Option<usize> {
    if name.contains(".h.") {
        let parts: Vec<&str> = name.split('.').collect();
        for (i, part) in parts.iter().enumerate() {
            if *part == "h" && i + 1 < parts.len() {
                return parts[i + 1].parse().ok();
            }
        }
    }
    None
}

/// PyTorch í…ì„œ íŒŒì¼ ë¡œë“œ (extract_weights.py í˜•ì‹)
fn load_tensor(path: &Path) -> Result<(Vec<f32>, Vec<usize>)> {
    // ê°„ë‹¨í•œ ë°”ì´ë„ˆë¦¬ í˜•ì‹ ê°€ì •:
    // [shape_len:u32][shape:u32*shape_len][data:f32*product(shape)]
    
    let data = fs::read(path)?;
    let mut cursor = 0;
    
    // Shape ê¸¸ì´ ì½ê¸°
    let shape_len = u32::from_le_bytes([
        data[cursor], data[cursor+1], data[cursor+2], data[cursor+3]
    ]) as usize;
    cursor += 4;
    
    // Shape ì½ê¸°
    let mut shape = Vec::with_capacity(shape_len);
    for _ in 0..shape_len {
        let dim = u32::from_le_bytes([
            data[cursor], data[cursor+1], data[cursor+2], data[cursor+3]
        ]) as usize;
        shape.push(dim);
        cursor += 4;
    }
    
    // ë°ì´í„° ì½ê¸°
    let total_elements: usize = shape.iter().product();
    let mut tensor_data = Vec::with_capacity(total_elements);
    
    for _ in 0..total_elements {
        let value = f32::from_le_bytes([
            data[cursor], data[cursor+1], data[cursor+2], data[cursor+3]
        ]);
        tensor_data.push(value);
        cursor += 4;
    }
    
    Ok((tensor_data, shape))
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_layer_number_extraction() {
        assert_eq!(extract_layer_number("transformer.h.0.attn.c_attn.weight"), Some(0));
        assert_eq!(extract_layer_number("transformer.h.11.mlp.c_fc.weight"), Some(11));
        assert_eq!(extract_layer_number("transformer.wte.weight"), None);
    }
} 