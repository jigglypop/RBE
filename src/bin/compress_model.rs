use std::path::Path;
use anyhow::Result;
use indicatif::{ProgressBar, ProgressStyle};
use rbe_llm::packed_params::{HybridEncodedBlock, TransformType};
use rbe_llm::encoder::AutoOptimizedEncoder;
use std::collections::HashMap;
use std::fs::{self, File};
use std::io::{self, Read, Write};
use serde_json::{Value, Map};

/// numpy íŒŒì¼ í—¤ë” ì½ê¸°
fn read_npy_header(file: &mut File) -> Result<(Vec<usize>, usize)> {
    let mut magic = [0u8; 6];
    file.read_exact(&mut magic)?;
    
    if &magic != b"\x93NUMPY" {
        return Err(anyhow::anyhow!("Invalid numpy file"));
    }
    
    let mut version = [0u8; 2];
    file.read_exact(&mut version)?;
    
    let header_len = if version[0] == 1 {
        let mut len_bytes = [0u8; 2];
        file.read_exact(&mut len_bytes)?;
        u16::from_le_bytes(len_bytes) as usize
    } else {
        let mut len_bytes = [0u8; 4];
        file.read_exact(&mut len_bytes)?;
        u32::from_le_bytes(len_bytes) as usize
    };
    
    let mut header = vec![0u8; header_len];
    file.read_exact(&mut header)?;
    let header_str = String::from_utf8_lossy(&header);
    
    // shape ì¶”ì¶œ
    let shape_start = header_str.find("'shape': (").unwrap() + 10;
    let shape_end = header_str[shape_start..].find(')').unwrap() + shape_start;
    let shape_str = &header_str[shape_start..shape_end];
    
    let shape: Vec<usize> = shape_str.split(", ")
        .filter(|s| !s.is_empty())
        .map(|s| s.trim_end_matches(',').parse().unwrap())
        .collect();
    
    let total_size = shape.iter().product();
    
    Ok((shape, total_size))
}

/// numpy íŒŒì¼ì—ì„œ float32 ë°ì´í„° ì½ê¸°
fn read_npy_data(path: &Path) -> Result<(Vec<f32>, Vec<usize>)> {
    let mut file = File::open(path)?;
    let (shape, total_size) = read_npy_header(&mut file)?;
    
    let mut buffer = vec![0u8; total_size * 4];
    file.read_exact(&mut buffer)?;
    
    let data: Vec<f32> = buffer.chunks_exact(4)
        .map(|chunk| f32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]))
        .collect();
    
    Ok((data, shape))
}

#[tokio::main]
async fn main() -> Result<()> {
    println!("ğŸš€ KoGPT2 ëª¨ë¸ ì••ì¶• ì‹œì‘ (numpy íŒŒì¼ ì‚¬ìš©)");
    
    let weights_dir = Path::new("models/skt-kogpt2-base-v2/weights");
    let metadata_path = weights_dir.join("metadata.json");
    
    if !metadata_path.exists() {
        println!("âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. extract_weights.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.");
        return Err(anyhow::anyhow!("Metadata file not found"));
    }
    
    // ë©”íƒ€ë°ì´í„° ë¡œë“œ
    let metadata_str = fs::read_to_string(&metadata_path)?;
    let metadata: Map<String, Value> = serde_json::from_str(&metadata_str)?;
    
    println!("âœ… ë°œê²¬ëœ ë ˆì´ì–´: {} ê°œ", metadata.len());
    
    // ì••ì¶• ì„¤ì •ë“¤
    let configs = vec![
        ("insane", 8, 128, TransformType::Dwt),     // ë¯¸ì¹œ ì••ì¶•! 128Â²/8 = 2048x!
        ("ultra", 16, 128, TransformType::Dwt),     // ì´ˆì••ì¶• 128Â²/16 = 1024x!
        ("extreme", 32, 128, TransformType::Dwt),   // ê·¹ë„ ì••ì¶• 128Â²/32 = 512x!
        ("high", 64, 128, TransformType::Dwt),      // ê³ ì••ì¶• 128Â²/64 = 256x!
        ("balanced", 128, 128, TransformType::Dwt), // ê· í˜• 128Â²/128 = 128x!
        ("lossless", 2000, 64, TransformType::Adaptive), // ê±°ì˜ ë¬´ì†ì‹¤
    ];
    
    // ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    fs::create_dir_all("models/compressed")?;
    
    for (name, coeffs, block_size, transform_type) in configs {
        println!("\nğŸ”§ ì••ì¶• í”„ë¡œíŒŒì¼: {} (ê³„ìˆ˜: {}, ë¸”ë¡: {}x{}, ë³€í™˜: {:?})", 
                 name, coeffs, block_size, block_size, transform_type);
        
        let mut compressed_weights = HashMap::new();
        let mut total_original_size = 0u64;
        let mut total_compressed_size = 0u64;
        let mut total_rmse = 0.0;
        let mut count = 0;
        
        // í”„ë¡œê·¸ë ˆìŠ¤ ë°”
        let pb = ProgressBar::new(metadata.len() as u64);
        pb.set_style(
            ProgressStyle::default_bar()
                .template("[{bar:40.cyan/blue}] {pos}/{len} {msg}")
                .unwrap()
                .progress_chars("â–ˆâ–ˆâ–‘"),
        );
        
        // AutoOptimizedEncoderì˜ compress_multi.rs ë¡œì§ ì‚¬ìš©
        println!("ğŸ“Š ë¸”ë¡ í¬ê¸° {}x{}, ê³„ìˆ˜: {}, ë³€í™˜: {:?}", 
                 block_size, block_size, coeffs, transform_type);
        
        // ê° ë ˆì´ì–´ ì••ì¶•
        for (layer_idx, (layer_name, layer_info)) in metadata.iter().enumerate() {
            println!("\nğŸ”„ [{}/{}] ë ˆì´ì–´ ì²˜ë¦¬ ì¤‘: {}", layer_idx + 1, metadata.len(), layer_name);
            pb.set_message(format!("ì••ì¶• ì¤‘: {}", layer_name));
            
            if let Some(info_obj) = layer_info.as_object() {
                if let (Some(_shape_val), Some(file_val)) = 
                    (info_obj.get("shape"), info_obj.get("file")) {
                    
                    let file_name = file_val.as_str().unwrap();
                    let npy_path = weights_dir.join(file_name);
                    
                    // numpy íŒŒì¼ ì½ê¸°
                    match read_npy_data(&npy_path) {
                        Ok((data, shape)) => {
                            // 2D ê°€ì¤‘ì¹˜ì¸ ê²½ìš°ë§Œ ì••ì¶• (Linear layers)
                            if shape.len() == 2 {
                                let height = shape[0];
                                let width = shape[1];
                                
                                // ê²©ì ë¶„í•  ë°©ì‹ìœ¼ë¡œ ë¹„ëŒ€ì¹­ ë§¤íŠ¸ë¦­ìŠ¤ ì••ì¶•
                                let blocks_per_row = (height + block_size - 1) / block_size;
                                let blocks_per_col = (width + block_size - 1) / block_size;
                                let total_blocks = blocks_per_row * blocks_per_col;
                                
                                println!("  ğŸ“ ë§¤íŠ¸ë¦­ìŠ¤: {}x{} â†’ {}x{} ê²©ì ({} ë¸”ë¡)", 
                                        height, width, blocks_per_row, blocks_per_col, total_blocks);
                                
                                let mut encoded_blocks = Vec::new();
                                let mut total_block_rmse = 0.0;
                                
                                for block_row in 0..blocks_per_row {
                                    for block_col in 0..blocks_per_col {
                                        let start_i = block_row * block_size;
                                        let start_j = block_col * block_size;
                                        let end_i = (start_i + block_size).min(height);
                                        let end_j = (start_j + block_size).min(width);
                                        
                                        // ë¸”ë¡ ë°ì´í„° ì¶”ì¶œ (íŒ¨ë”© í¬í•¨)
                                        let mut block_data = vec![0.0f32; block_size * block_size];
                                        for i in 0..(end_i - start_i) {
                                            for j in 0..(end_j - start_j) {
                                                let src_idx = (start_i + i) * width + (start_j + j);
                                                let dst_idx = i * block_size + j;
                                                block_data[dst_idx] = data[src_idx];
                                            }
                                        }
                                        
                                        // ë¸”ë¡ë³„ ì••ì¶• (height, width, block_size, coeffs, transform_type)
                                        match AutoOptimizedEncoder::compress_with_profile(
                                            &block_data, 
                                            block_size,  // height
                                            block_size,  // width
                                            block_size,  // block_size
                                            coeffs, 
                                            transform_type
                                        ) {
                                            Ok((mut block_compressed, _, _, block_rmse)) => {
                                                total_block_rmse += block_rmse;
                                                encoded_blocks.append(&mut block_compressed);
                                            },
                                            Err(e) => {
                                                println!("  âŒ ë¸”ë¡ ì••ì¶• ì‹¤íŒ¨: {}", e);
                                            }
                                        }
                                    }
                                }
                                
                                let avg_rmse = total_block_rmse / total_blocks as f32;
                                
                                // ì••ì¶•ë¥  ê³„ì‚°
                                let original_size = data.len() * 4;
                                let compressed_size = encoded_blocks.len() * std::mem::size_of::<HybridEncodedBlock>();
                                let compression_ratio = original_size as f32 / compressed_size as f32;
                                
                                println!("  âœ… ê²©ì ì••ì¶• ì™„ë£Œ: RMSE {:.6}, ì••ì¶•ë¥  {:.1}x ({} ë¸”ë¡)", 
                                        avg_rmse, compression_ratio, total_blocks);
                                
                                total_rmse += avg_rmse;
                                count += 1;
                                total_original_size += original_size as u64;
                                total_compressed_size += compressed_size as u64;
                                
                                compressed_weights.insert(layer_name.clone(), encoded_blocks);
                            }
                        }
                        Err(e) => {
                            eprintln!("âŒ {} ì½ê¸° ì‹¤íŒ¨: {}", layer_name, e);
                        }
                    }
                }
            }
            
            pb.inc(1);
        }
        
        pb.finish_with_message("ì••ì¶• ì™„ë£Œ!");
        
        // ê²°ê³¼ ì¶œë ¥
        let compression_ratio = if total_compressed_size > 0 {
            total_original_size as f32 / total_compressed_size as f32
        } else {
            0.0
        };
        let avg_rmse = if count > 0 { total_rmse / count as f32 } else { 0.0 };
        
        println!("âœ… ì••ì¶• ì™„ë£Œ!");
        println!("  - ì›ë³¸: {:.2} MB", total_original_size as f32 / 1_048_576.0);
        println!("  - ì••ì¶•: {:.2} MB", total_compressed_size as f32 / 1_048_576.0);
        println!("  - ì••ì¶•ë¥ : {:.1}x", compression_ratio);
        println!("  - í‰ê·  RMSE: {:.6}", avg_rmse);
        println!("  - ì••ì¶•ëœ ë ˆì´ì–´: {}", count);
        
        // ì••ì¶•ëœ ëª¨ë¸ ì €ì¥
        let output_path = format!("models/compressed/kogpt2_{}.bin", name);
        save_compressed_model(&compressed_weights, &output_path)?;
        println!("ğŸ’¾ ì €ì¥ ì™„ë£Œ: {}", output_path);
    }
    
    println!("\nâœ… ëª¨ë“  ì••ì¶• í”„ë¡œíŒŒì¼ ì™„ë£Œ!");
    Ok(())
}

fn save_compressed_model(weights: &HashMap<String, Vec<HybridEncodedBlock>>, path: &str) -> Result<()> {
    let summary = format!(
        "Compressed model with {} layers, total {} blocks", 
        weights.len(),
        weights.values().map(|v| v.len()).sum::<usize>()
    );
    fs::write(path, summary)?;
    Ok(())
} 