use rbe_llm::sllm::{
    ModelDownloader, SLLMCompressor, RBEInferenceEngine, CompressionConfig, 
    SLLMBenchmark, BenchmarkConfig
};
use clap::{Arg, Command};
use std::path::PathBuf;
use std::process;

#[tokio::main]
async fn main() {
    env_logger::init();
    
    let matches = Command::new("RBE CLI")
        .version("1.0.0")
        .about("í‘¸ì•µì¹´ë ˆ ë³¼ ê¸°ë°˜ RBE ëª¨ë¸ CLI ë„êµ¬")
        .subcommand(
            Command::new("download")
                .about("HuggingFaceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
                .arg(
                    Arg::new("model-id")
                        .required(true)
                        .help("HuggingFace ëª¨ë¸ ID (ì˜ˆ: skt/kogpt2-base-v2)")
                )
                .arg(
                    Arg::new("output-dir")
                        .long("output")
                        .short('o')
                        .value_name("DIR")
                        .help("ì¶œë ¥ ë””ë ‰í† ë¦¬")
                        .default_value("./models")
                )
        )
        .subcommand(
            Command::new("compress")
                .about("ëª¨ë¸ ì••ì¶•")
                .arg(
                    Arg::new("model-path")
                        .required(true)
                        .help("ì••ì¶•í•  ëª¨ë¸ ê²½ë¡œ")
                )
                .arg(
                    Arg::new("output-path")
                        .required(true)
                        .help("ì••ì¶•ëœ ëª¨ë¸ ì¶œë ¥ ê²½ë¡œ")
                )
                .arg(
                    Arg::new("compression-level")
                        .long("level")
                        .short('l')
                        .value_name("LEVEL")
                        .help("ì••ì¶• ë ˆë²¨ (1-5)")
                        .default_value("3")
                )
                .arg(
                    Arg::new("block-size")
                        .long("block-size")
                        .value_name("SIZE")
                        .help("ë¸”ë¡ í¬ê¸°")
                        .default_value("32")
                )
                .arg(
                    Arg::new("coefficients")
                        .long("coefficients")
                        .short('c')
                        .value_name("COUNT")
                        .help("ì›¨ì´ë¸”ë¦¿ ê³„ìˆ˜ ê°œìˆ˜")
                        .default_value("500")
                )
        )
        .subcommand(
            Command::new("generate")
                .about("í…ìŠ¤íŠ¸ ìƒì„±")
                .arg(
                    Arg::new("compressed-model")
                        .required(true)
                        .help("ì••ì¶•ëœ ëª¨ë¸ ê²½ë¡œ")
                )
                .arg(
                    Arg::new("original-model")
                        .required(true)
                        .help("ì›ë³¸ ëª¨ë¸ ê²½ë¡œ (ì„¤ì •ìš©)")
                )
                .arg(
                    Arg::new("prompt")
                        .required(true)
                        .help("ìƒì„±í•  í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸")
                )
                .arg(
                    Arg::new("max-tokens")
                        .long("max-tokens")
                        .value_name("TOKENS")
                        .help("ìµœëŒ€ ìƒì„± í† í° ìˆ˜")
                        .default_value("50")
                )
                .arg(
                    Arg::new("temperature")
                        .long("temperature")
                        .value_name("TEMP")
                        .help("Temperature ê°’ (0.0-2.0)")
                        .default_value("0.7")
                )
                .arg(
                    Arg::new("top-p")
                        .long("top-p")
                        .value_name("TOP_P")
                        .help("Top-p ê°’ (0.0-1.0)")
                        .default_value("0.9")
                )
        )
        .subcommand(
            Command::new("benchmark")
                .about("ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰")
                .arg(
                    Arg::new("iterations")
                        .long("iterations")
                        .short('i')
                        .value_name("COUNT")
                        .help("ë°˜ë³µ íšŸìˆ˜")
                        .default_value("10")
                )
                .arg(
                    Arg::new("save-results")
                        .long("save")
                        .short('s')
                        .value_name("FILE")
                        .help("ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥")
                )
        )
        .subcommand(
            Command::new("info")
                .about("ì••ì¶•ëœ ëª¨ë¸ ì •ë³´ í™•ì¸")
                .arg(
                    Arg::new("model-path")
                        .required(true)
                        .help("ì••ì¶•ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
                )
        )
        .get_matches();
    
    let result = match matches.subcommand() {
        Some(("download", sub_matches)) => handle_download(sub_matches).await,
        Some(("compress", sub_matches)) => handle_compress(sub_matches).await,
        Some(("generate", sub_matches)) => handle_generate(sub_matches).await,
        Some(("benchmark", sub_matches)) => handle_benchmark(sub_matches).await,
        Some(("info", sub_matches)) => handle_info(sub_matches).await,
        _ => {
            println!("âŒ ëª…ë ¹ì„ ì§€ì •í•´ì£¼ì„¸ìš”. --helpë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.");
            process::exit(1);
        }
    };
    
    if let Err(e) = result {
        eprintln!("âŒ ì˜¤ë¥˜: {}", e);
        process::exit(1);
    }
}

async fn handle_download(matches: &clap::ArgMatches) -> Result<(), Box<dyn std::error::Error>> {
    let model_id = matches.get_one::<String>("model-id").unwrap();
    let output_dir = matches.get_one::<String>("output-dir").unwrap();
    
    println!("ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {}", model_id);
    
    let downloader = ModelDownloader::new(model_id);
    let model_path = downloader.download().await?;
    
    println!("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {:?}", model_path);
    Ok(())
}

async fn handle_compress(matches: &clap::ArgMatches) -> Result<(), Box<dyn std::error::Error>> {
    let model_path = PathBuf::from(matches.get_one::<String>("model-path").unwrap());
    let output_path = PathBuf::from(matches.get_one::<String>("output-path").unwrap());
    let compression_level = matches.get_one::<String>("compression-level").unwrap().parse()?;
    let block_size = matches.get_one::<String>("block-size").unwrap().parse()?;
    let coefficients = matches.get_one::<String>("coefficients").unwrap().parse()?;
    
    println!("ğŸ—œï¸ ëª¨ë¸ ì••ì¶• ì‹œì‘:");
    println!("   ì…ë ¥: {:?}", model_path);
    println!("   ì¶œë ¥: {:?}", output_path);
    println!("   ì••ì¶• ë ˆë²¨: {}", compression_level);
    println!("   ë¸”ë¡ í¬ê¸°: {}", block_size);
    println!("   ê³„ìˆ˜ ê°œìˆ˜: {}", coefficients);
    
    let config = CompressionConfig {
        wavelet_coefficients: coefficients,
        block_size,
        compression_level,
        num_threads: num_cpus::get(),
        show_progress: true,
    };
    
    let compressor = SLLMCompressor::new(config);
    let compressed_model = compressor.compress_safetensors_model(&model_path, &output_path).await?;
    
    println!("\nğŸ† ì••ì¶• ì™„ë£Œ!");
    println!("   ì••ì¶•ë¥ : {:.1}:1", compressed_model.total_compression_ratio);
    println!("   í‰ê·  RMSE: {:.6}", compressed_model.average_rmse);
    println!("   ì••ì¶• ì‹œê°„: {:.2}ì´ˆ", compressed_model.compression_time);
    
    Ok(())
}

async fn handle_generate(matches: &clap::ArgMatches) -> Result<(), Box<dyn std::error::Error>> {
    let compressed_model = PathBuf::from(matches.get_one::<String>("compressed-model").unwrap());
    let original_model = PathBuf::from(matches.get_one::<String>("original-model").unwrap());
    let prompt = matches.get_one::<String>("prompt").unwrap();
    let max_tokens = matches.get_one::<String>("max-tokens").unwrap().parse()?;
    let temperature = matches.get_one::<String>("temperature").unwrap().parse()?;
    let top_p = matches.get_one::<String>("top-p").unwrap().parse()?;
    
    println!("ğŸ’­ í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘:");
    println!("   í”„ë¡¬í”„íŠ¸: '{}'", prompt);
    println!("   ìµœëŒ€ í† í°: {}", max_tokens);
    println!("   Temperature: {}", temperature);
    println!("   Top-p: {}", top_p);
    
    let engine = RBEInferenceEngine::from_compressed_model(&compressed_model, &original_model).await?;
    engine.print_model_info();
    
    let generated_text = engine.generate_text(prompt, max_tokens, temperature, top_p)?;
    
    println!("\nğŸ“ ìƒì„±ëœ í…ìŠ¤íŠ¸:");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("{}", generated_text);
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    
    Ok(())
}

async fn handle_benchmark(matches: &clap::ArgMatches) -> Result<(), Box<dyn std::error::Error>> {
    let iterations = matches.get_one::<String>("iterations").unwrap().parse()?;
    let save_path = matches.get_one::<String>("save-results");
    
    println!("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ({}íšŒ ë°˜ë³µ)", iterations);
    
    let config = BenchmarkConfig {
        iterations,
        warmup_iterations: 3,
        batch_size: 32,
        verbose: true,
    };
    
    let mut benchmark = SLLMBenchmark::new(config);
    
    // RBE ì••ì¶• ë²¤ì¹˜ë§ˆí¬
    let matrix_sizes = vec![
        (256, 256),
        (512, 512),
        (1024, 1024),
        (2048, 2048),
    ];
    benchmark.benchmark_rbe_compression(&matrix_sizes);
    
    // í† í° ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬
    let text_lengths = vec![100, 500, 1000, 5000];
    benchmark.benchmark_token_processing(&text_lengths);
    
    // ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬
    let context_lengths = vec![128, 256, 512, 1024];
    benchmark.benchmark_inference_speed(&context_lengths);
    
    // ìš”ì•½ ì¶œë ¥
    benchmark.print_summary();
    
    // ê²°ê³¼ ì €ì¥
    if let Some(save_path) = save_path {
        benchmark.save_results(save_path)?;
    }
    
    Ok(())
}

async fn handle_info(matches: &clap::ArgMatches) -> Result<(), Box<dyn std::error::Error>> {
    let model_path = matches.get_one::<String>("model-path").unwrap();
    
    println!("ğŸ“‹ ëª¨ë¸ ì •ë³´ ì¡°íšŒ: {}", model_path);
    
    let content = std::fs::read_to_string(model_path)?;
    let compressed_model: rbe_llm::sllm::CompressedModel = serde_json::from_str(&content)?;
    
    println!("\nğŸ† === ì••ì¶•ëœ ëª¨ë¸ ì •ë³´ ===");
    println!("ëª¨ë¸ëª…: {}", compressed_model.model_name);
    println!("ì›ë³¸ í¬ê¸°: {:.2} MB", compressed_model.original_total_size as f64 / 1_048_576.0);
    println!("ì••ì¶• í¬ê¸°: {:.2} KB", compressed_model.compressed_total_size as f64 / 1024.0);
    println!("ì••ì¶•ë¥ : {:.1}:1", compressed_model.total_compression_ratio);
    println!("í‰ê·  RMSE: {:.6}", compressed_model.average_rmse);
    println!("ì••ì¶• ì‹œê°„: {:.2}ì´ˆ", compressed_model.compression_time);
    
    // í’ˆì§ˆ ë“±ê¸‰
    let quality = if compressed_model.average_rmse < 0.001 { "ğŸ¥‡ Sê¸‰" }
    else if compressed_model.average_rmse < 0.01 { "ğŸ¥ˆ Aê¸‰" }
    else if compressed_model.average_rmse < 0.05 { "ğŸ¥‰ Bê¸‰" }
    else { "Cê¸‰" };
    
    println!("ì••ì¶• í’ˆì§ˆ: {}", quality);
    
    println!("\nğŸ—œï¸ ì••ì¶•ëœ ë ˆì´ì–´:");
    for (name, layer) in &compressed_model.layers {
        println!("  {}: {}Ã—{} (RMSE: {:.6})", 
                 name, layer.shape[0], layer.shape[1], layer.rmse);
    }
    
    Ok(())
} 