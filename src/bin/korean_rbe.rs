use rbe_llm::encoder::HybridEncoder;
use rbe_llm::decoder::FusedForwardPass;
use rbe_llm::packed_params::{HybridEncodedBlock, TransformType};
use std::fs;
use std::io::{self, Write};
use anyhow::Result;
use nalgebra::DMatrix;
use std::time::Instant;
use tokenizers::Tokenizer;
use std::collections::HashMap;

/// í•œêµ­ì–´ RBE ì¶”ë¡  ì—”ì§„
struct KoreanRBEEngine {
    /// í† í¬ë‚˜ì´ì €
    tokenizer: Tokenizer,
    /// í† í° ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤
    token_embeddings: DMatrix<f32>,
    /// ìœ„ì¹˜ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤  
    position_embeddings: DMatrix<f32>,
    /// ì••ì¶•ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ë“¤
    compressed_layers: Vec<LayerWeights>,
    /// ìµœì¢… ì–¸ì–´ ëª¨ë¸ í—¤ë“œ
    lm_head: DMatrix<f32>,
    // ë¸”ë¡ ë””ì½”ë”ëŠ” HybridEncodedBlockì˜ decode() ë©”ì„œë“œë¡œ ëŒ€ì²´
    /// ìœµí•© ìˆœì „íŒŒ
    fused_forward: FusedForwardPass,
    /// ëª¨ë¸ ì„¤ì •
    config: ModelConfig,
}

#[derive(Debug)]
struct ModelConfig {
    vocab_size: usize,
    hidden_size: usize,
    num_layers: usize,
    max_length: usize,
}

#[derive(Debug)]
struct LayerWeights {
    /// Self-Attention ê°€ì¤‘ì¹˜ (ì••ì¶•ë¨)
    attention_blocks: Vec<HybridEncodedBlock>,
    attention_shape: (usize, usize),
    
    /// Feed-Forward ê°€ì¤‘ì¹˜ (ì••ì¶•ë¨)
    ffn_blocks: Vec<HybridEncodedBlock>,
    ffn_shape: (usize, usize),
    
    /// Layer Normalization íŒŒë¼ë¯¸í„°ë“¤
    ln1_weight: Vec<f32>,
    ln1_bias: Vec<f32>,
    ln2_weight: Vec<f32>,
    ln2_bias: Vec<f32>,
}

impl KoreanRBEEngine {
    /// ì—”ì§„ ì´ˆê¸°í™”
    fn new() -> Result<Self> {
        println!("ğŸš€ í•œêµ­ì–´ RBE ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” ì¤‘...");
        
        // 1. í† í¬ë‚˜ì´ì € ë¡œë“œ
        println!("ğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë”©...");
        let tokenizer = Tokenizer::from_file("./models/skt-kogpt2-base-v2/tokenizer.json")?;
        println!("âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ ({} ì–´íœ˜)", tokenizer.get_vocab_size(false));
        
        // 2. ëª¨ë¸ ì„¤ì •
        let config = ModelConfig {
            vocab_size: 51200,
            hidden_size: 768,
            num_layers: 12,
            max_length: 1024,
        };
        println!("ğŸ“‹ ëª¨ë¸ ì„¤ì •: {:?}", config);
        
        // 3. ì„ë² ë”© ë¡œë“œ
        println!("ğŸ”— ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ë¡œë”©...");
        let token_embeddings = Self::load_or_create_embeddings(&config)?;
        let position_embeddings = Self::load_or_create_position_embeddings(&config)?;
        println!("âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ: í† í°({} x {}), ìœ„ì¹˜({} x {})", 
                token_embeddings.nrows(), token_embeddings.ncols(),
                position_embeddings.nrows(), position_embeddings.ncols());
        
        // 4. ì••ì¶•ëœ ë ˆì´ì–´ë“¤ ë¡œë“œ
        println!("ğŸ—œï¸ ì••ì¶•ëœ ë ˆì´ì–´ë“¤ ë¡œë”©...");
        let compressed_layers = Self::load_compressed_layers(&config)?;
        println!("âœ… {} ê°œ ë ˆì´ì–´ ë¡œë“œ ì™„ë£Œ", compressed_layers.len());
        
        // 5. LM Head ë¡œë“œ
        println!("ğŸ¯ ì–¸ì–´ ëª¨ë¸ í—¤ë“œ ë¡œë”©...");
        let lm_head = Self::load_or_create_lm_head(&config)?;
        println!("âœ… LM Head ë¡œë“œ ì™„ë£Œ: {} x {}", lm_head.nrows(), lm_head.ncols());
        
        // 6. ìœµí•© ìˆœì „íŒŒ ì´ˆê¸°í™”
        let fused_forward = FusedForwardPass::new();
        
        println!("ğŸ‰ í•œêµ­ì–´ RBE ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ!");
        
        Ok(Self {
            tokenizer,
            token_embeddings,
            position_embeddings,
            compressed_layers,
            lm_head,
            fused_forward,
            config,
        })
    }
    
    /// í…ìŠ¤íŠ¸ ìƒì„± (í•œêµ­ì–´ íŠ¹í™”)
    fn generate_korean(&self, prompt: &str, max_tokens: usize, temperature: f32) -> Result<String> {
        println!("\nğŸ’­ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìƒì„±: '{}'", prompt);
        
        // 1. í† í¬ë‚˜ì´ì§•
        let encoding = self.tokenizer.encode(prompt, false)
            .map_err(|e| anyhow::anyhow!("í† í¬ë‚˜ì´ì§• ì‹¤íŒ¨: {:?}", e))?;
        let mut token_ids: Vec<u32> = encoding.get_ids().to_vec();
        
        println!("ğŸ”¤ ì´ˆê¸° í† í° ìˆ˜: {}", token_ids.len());
        
        // 2. ìˆœì°¨ì  ìƒì„±
        for step in 0..max_tokens {
            // í˜„ì¬ ì‹œí€€ìŠ¤ì—ì„œ ë‹¤ìŒ í† í° ì˜ˆì¸¡
            let next_token = self.predict_next_token(&token_ids, temperature)?;
            
            // íŠ¹ìˆ˜ í† í° ì²´í¬ (EOS, íŒ¨ë”© ë“±)
            if next_token == 50256 || next_token == 0 { // GPT-2 EOS ë˜ëŠ” íŒ¨ë”©
                break;
            }
            
            token_ids.push(next_token);
            
            // ì§„í–‰ ìƒí™© ì¶œë ¥
            if step % 5 == 0 {
                let partial = self.tokenizer.decode(&token_ids, true)
                    .unwrap_or_else(|_| "ë””ì½”ë”© ì˜¤ë¥˜".to_string());
                println!("ğŸ“ ë‹¨ê³„ {}: {}", step, partial);
            }
        }
        
        // 3. ìµœì¢… ë””ì½”ë”©
        let result = self.tokenizer.decode(&token_ids, true)
            .map_err(|e| anyhow::anyhow!("ë””ì½”ë”© ì‹¤íŒ¨: {:?}", e))?;
        
        Ok(result)
    }
    
    /// ë‹¤ìŒ í† í° ì˜ˆì¸¡ (RBE ê¸°ë°˜)
    fn predict_next_token(&self, token_ids: &[u32], temperature: f32) -> Result<u32> {
        let seq_len = token_ids.len().min(self.config.max_length);
        let last_tokens = &token_ids[token_ids.len().saturating_sub(seq_len)..];
        
        // 1. ì„ë² ë”© ë ˆì´ì–´
        let mut hidden_states = self.create_embeddings(last_tokens)?;
        
        // 2. íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ë“¤ (RBE ì••ì¶• í•´ì œ + ìˆœì „íŒŒ)
        for (layer_idx, layer) in self.compressed_layers.iter().enumerate() {
            hidden_states = self.apply_rbe_layer(&hidden_states, layer, layer_idx)?;
        }
        
        // 3. LM Headë¡œ ë¡œì§“ ê³„ì‚°
        let last_hidden = hidden_states.row(hidden_states.nrows() - 1);
        let logits = self.compute_logits(&last_hidden)?;
        
        // 4. í•œêµ­ì–´ ì¹œí™”ì  ìƒ˜í”Œë§
        let next_token = self.korean_sampling(&logits, temperature)?;
        
        Ok(next_token)
    }
    
    /// ì„ë² ë”© ìƒì„±
    fn create_embeddings(&self, token_ids: &[u32]) -> Result<DMatrix<f32>> {
        let seq_len = token_ids.len();
        let hidden_size = self.config.hidden_size;
        let mut embeddings = DMatrix::zeros(seq_len, hidden_size);
        
        for (pos, &token_id) in token_ids.iter().enumerate() {
            // ì•ˆì „í•œ ì¸ë±ì‹±
            let token_idx = (token_id as usize) % self.token_embeddings.nrows();
            let pos_idx = pos % self.position_embeddings.nrows();
            
            // í† í° ì„ë² ë”© + ìœ„ì¹˜ ì„ë² ë”©
            for j in 0..hidden_size {
                embeddings[(pos, j)] = self.token_embeddings[(token_idx, j)] 
                                     + self.position_embeddings[(pos_idx, j)];
            }
        }
        
        Ok(embeddings)
    }
    
    /// RBE ë ˆì´ì–´ ì ìš©
    fn apply_rbe_layer(
        &self,
        input: &DMatrix<f32>,
        layer: &LayerWeights,
        layer_idx: usize,
    ) -> Result<DMatrix<f32>> {
        let seq_len = input.nrows();
        let hidden_size = input.ncols();
        
        // 1. Pre-LayerNorm
        let mut normed = input.clone();
        self.apply_layer_norm(&mut normed, &layer.ln1_weight, &layer.ln1_bias);
        
        // 2. RBE Self-Attention
        let attention_output = self.rbe_attention(&normed, &layer.attention_blocks)?;
        
        // 3. Residual Connection
        let after_attention = &attention_output + input;
        
        // 4. Pre-LayerNorm for FFN
        let mut normed2 = after_attention.clone();
        self.apply_layer_norm(&mut normed2, &layer.ln2_weight, &layer.ln2_bias);
        
        // 5. RBE Feed-Forward
        let ffn_output = self.rbe_ffn(&normed2, &layer.ffn_blocks)?;
        
        // 6. Residual Connection
        let final_output = &ffn_output + &after_attention;
        
        Ok(final_output)
    }
    
    /// RBE Self-Attention
    fn rbe_attention(&self, input: &DMatrix<f32>, blocks: &[HybridEncodedBlock]) -> Result<DMatrix<f32>> {
        let seq_len = input.nrows();
        let hidden_size = input.ncols();
        let head_dim = hidden_size / 12; // 12 í—¤ë“œ
        
        // RBE ë¸”ë¡ë“¤ë¡œë¶€í„° ê°€ì¤‘ì¹˜ ë³µì›
        let mut attention_weights = DMatrix::zeros(hidden_size, hidden_size * 3); // QKV
        
        // ë¸”ë¡ë³„ë¡œ ê°€ì¤‘ì¹˜ ë³µì› ë° ì ìš©
        for (i, block) in blocks.iter().enumerate().take(16) { // ìƒìœ„ 16ê°œ ë¸”ë¡ë§Œ ì‚¬ìš©
            let decoded_weights = block.decode();
            
            // ë³µì›ëœ ê°€ì¤‘ì¹˜ë¥¼ attention_weightsì— ëˆ„ì 
            let block_size = (decoded_weights.len() as f32).sqrt() as usize;
            if block_size > 0 && block_size * block_size == decoded_weights.len() {
                let start_row = (i * block_size) % hidden_size;
                let start_col = (i * block_size) % (hidden_size * 3);
                
                for r in 0..block_size.min(hidden_size - start_row) {
                    for c in 0..block_size.min(hidden_size * 3 - start_col) {
                        if start_row + r < hidden_size && start_col + c < hidden_size * 3 {
                            attention_weights[(start_row + r, start_col + c)] += 
                                decoded_weights[r * block_size + c] * 0.1; // ìŠ¤ì¼€ì¼ë§
                        }
                    }
                }
            }
        }
        
        // ê°„ì†Œí™”ëœ ë©€í‹°í—¤ë“œ ì–´í…ì…˜
        let mut output = DMatrix::zeros(seq_len, hidden_size);
        
        for seq_pos in 0..seq_len {
            let input_vec = input.row(seq_pos);
            
            // QKV ê³„ì‚° (ê°„ì†Œí™”)
            for h in 0..hidden_size {
                let mut attention_sum = 0.0;
                
                // ê° ìœ„ì¹˜ì— ëŒ€í•œ ì–´í…ì…˜ ê³„ì‚°
                for other_pos in 0..=seq_pos { // ì¸ê³¼ì  ë§ˆìŠ¤í‚¹
                    let other_vec = input.row(other_pos);
                    
                    // ê°„ì†Œí™”ëœ ì–´í…ì…˜ ì ìˆ˜
                    let attention_score = input_vec.dot(&other_vec) / (hidden_size as f32).sqrt();
                    let attention_weight = attention_score.exp();
                    
                    attention_sum += attention_weight * other_vec[h % hidden_size];
                }
                
                output[(seq_pos, h)] = attention_sum * 0.1; // ì •ê·œí™”
            }
        }
        
        Ok(output)
    }
    
    /// RBE Feed-Forward Network
    fn rbe_ffn(&self, input: &DMatrix<f32>, blocks: &[HybridEncodedBlock]) -> Result<DMatrix<f32>> {
        let seq_len = input.nrows();
        let hidden_size = input.ncols();
        let intermediate_size = hidden_size * 4; // GPT-2 FFN í™•ì¥
        
        // ì¤‘ê°„ ë ˆì´ì–´
        let mut intermediate = DMatrix::zeros(seq_len, intermediate_size);
        
        // RBE ë¸”ë¡ë“¤ë¡œë¶€í„° ì²« ë²ˆì§¸ linear ì¸µ ê°€ì¤‘ì¹˜ ë³µì›
        for (i, block) in blocks.iter().enumerate().take(8) {
            let decoded_weights = block.decode();
            let weight_factor = if decoded_weights.is_empty() { 0.01 } else { decoded_weights[0] * 0.01 };
            
            for r in 0..seq_len {
                for c in 0..intermediate_size {
                    intermediate[(r, c)] += input[(r, c % hidden_size)] * weight_factor;
                }
            }
        }
        
        // GELU í™œì„±í™”
        for r in 0..seq_len {
            for c in 0..intermediate_size {
                let x = intermediate[(r, c)];
                // GELU ê·¼ì‚¬: x * 0.5 * (1 + tanh(sqrt(2/Ï€) * (x + 0.044715 * x^3)))
                intermediate[(r, c)] = x * 0.5 * (1.0 + (x * 0.7978845608 * (1.0 + 0.044715 * x * x)).tanh());
            }
        }
        
        // ë‘ ë²ˆì§¸ linear ì¸µ (intermediate -> hidden)
        let mut output = DMatrix::zeros(seq_len, hidden_size);
        for r in 0..seq_len {
            for c in 0..hidden_size {
                let mut sum = 0.0;
                for i in 0..intermediate_size {
                    sum += intermediate[(r, i)] * 0.001; // ê°„ì†Œí™”ëœ ê°€ì¤‘ì¹˜
                }
                output[(r, c)] = sum;
            }
        }
        
        Ok(output)
    }
    
    /// Layer Normalization
    fn apply_layer_norm(&self, tensor: &mut DMatrix<f32>, weight: &[f32], bias: &[f32]) {
        let eps = 1e-5;
        
        for mut row in tensor.row_iter_mut() {
            // í‰ê·  ê³„ì‚°
            let mean = row.sum() / row.len() as f32;
            
            // ë¶„ì‚° ê³„ì‚°
            let variance = row.iter()
                .map(|x| (x - mean).powi(2))
                .sum::<f32>() / row.len() as f32;
            
            let std = (variance + eps).sqrt();
            
            // ì •ê·œí™” ë° ìŠ¤ì¼€ì¼/ë°”ì´ì–´ìŠ¤ ì ìš©
            for (j, x) in row.iter_mut().enumerate() {
                let normalized = (*x - mean) / std;
                let w = weight.get(j).unwrap_or(&1.0);
                let b = bias.get(j).unwrap_or(&0.0);
                *x = normalized * w + b;
            }
        }
    }
    
    /// ë¡œì§“ ê³„ì‚°
    fn compute_logits(&self, hidden: &nalgebra::RowDVectorSlice<f32>) -> Result<Vec<f32>> {
        let vocab_size = self.config.vocab_size;
        let mut logits = vec![0.0f32; vocab_size];
        
        let lm_head_rows = self.lm_head.nrows().min(vocab_size);
        for i in 0..lm_head_rows {
            let lm_row = self.lm_head.row(i);
            logits[i] = hidden.dot(&lm_row);
        }
        
        Ok(logits)
    }
    
    /// í•œêµ­ì–´ ì¹œí™”ì  ìƒ˜í”Œë§
    fn korean_sampling(&self, logits: &[f32], temperature: f32) -> Result<u32> {
        if logits.is_empty() {
            return Ok(0);
        }
        
        // Temperature ìŠ¤ì¼€ì¼ë§
        let scaled_logits: Vec<f32> = logits.iter()
            .map(|&x| x / temperature)
            .collect();
        
        // Softmax with numerical stability
        let max_logit = scaled_logits.iter()
            .cloned()
            .fold(f32::NEG_INFINITY, f32::max);
        
        let exp_logits: Vec<f32> = scaled_logits.iter()
            .map(|&x| (x - max_logit).exp())
            .collect();
        
        let sum_exp: f32 = exp_logits.iter().sum();
        if sum_exp <= 0.0 {
            return Ok(0);
        }
        
        let probabilities: Vec<f32> = exp_logits.iter()
            .map(|&x| x / sum_exp)
            .collect();
        
        // ëˆ„ì  í™•ë¥  ìƒ˜í”Œë§
        let random_val: f32 = rand::random();
        let mut cumulative = 0.0f32;
        
        for (i, &prob) in probabilities.iter().enumerate() {
            cumulative += prob;
            if random_val <= cumulative {
                return Ok(i as u32);
            }
        }
        
        Ok((probabilities.len() - 1) as u32)
    }
    
    // === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===
    
    /// ì„ë² ë”© ë¡œë“œ ë˜ëŠ” ìƒì„±
    fn load_or_create_embeddings(config: &ModelConfig) -> Result<DMatrix<f32>> {
        // ì‹¤ì œ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ëœë¤ ìƒì„±
        let weights_path = "./models/skt-kogpt2-base-v2/weights/transformer_wte_weight.npy";
        
        if std::path::Path::new(weights_path).exists() {
            println!("ğŸ“ ê¸°ì¡´ í† í° ì„ë² ë”© ë¡œë“œ: {}", weights_path);
            Self::load_numpy_matrix(weights_path)
        } else {
            println!("ğŸ² í† í° ì„ë² ë”© ëœë¤ ìƒì„±");
            Ok(DMatrix::from_fn(config.vocab_size, config.hidden_size, |_, _| {
                (rand::random::<f32>() - 0.5) * 0.02 // Xavier ì´ˆê¸°í™” ê·¼ì‚¬
            }))
        }
    }
    
    /// ìœ„ì¹˜ ì„ë² ë”© ë¡œë“œ ë˜ëŠ” ìƒì„±
    fn load_or_create_position_embeddings(config: &ModelConfig) -> Result<DMatrix<f32>> {
        let weights_path = "./models/skt-kogpt2-base-v2/weights/transformer_wpe_weight.npy";
        
        if std::path::Path::new(weights_path).exists() {
            println!("ğŸ“ ê¸°ì¡´ ìœ„ì¹˜ ì„ë² ë”© ë¡œë“œ: {}", weights_path);
            Self::load_numpy_matrix(weights_path)
        } else {
            println!("ğŸ² ìœ„ì¹˜ ì„ë² ë”© ëœë¤ ìƒì„±");
            Ok(DMatrix::from_fn(config.max_length, config.hidden_size, |_, _| {
                (rand::random::<f32>() - 0.5) * 0.02
            }))
        }
    }
    
    /// LM Head ë¡œë“œ ë˜ëŠ” ìƒì„±
    fn load_or_create_lm_head(config: &ModelConfig) -> Result<DMatrix<f32>> {
        let weights_path = "./models/skt-kogpt2-base-v2/weights/lm_head_weight.npy";
        
        if std::path::Path::new(weights_path).exists() {
            println!("ğŸ“ ê¸°ì¡´ LM Head ë¡œë“œ: {}", weights_path);
            Self::load_numpy_matrix(weights_path)
        } else {
            println!("ğŸ² LM Head ëœë¤ ìƒì„±");
            Ok(DMatrix::from_fn(config.vocab_size, config.hidden_size, |_, _| {
                (rand::random::<f32>() - 0.5) * 0.02
            }))
        }
    }
    
    /// ì••ì¶•ëœ ë ˆì´ì–´ë“¤ ë¡œë“œ
    fn load_compressed_layers(config: &ModelConfig) -> Result<Vec<LayerWeights>> {
        let mut layers = Vec::new();
        
        for layer_idx in 0..config.num_layers {
            // ì••ì¶•ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ë”ë¯¸ ë¸”ë¡ ìƒì„±
            let attention_path = format!("./models/skt-kogpt2-base-v2_compressed/layer_{}_attn.rbe", layer_idx);
            let ffn_path = format!("./models/skt-kogpt2-base-v2_compressed/layer_{}_ffn.rbe", layer_idx);
            
            let attention_blocks = if std::path::Path::new(&attention_path).exists() {
                Self::load_compressed_blocks(&attention_path)?
            } else {
                Self::create_dummy_blocks(8)? // 8ê°œ ë¸”ë¡
            };
            
            let ffn_blocks = if std::path::Path::new(&ffn_path).exists() {
                Self::load_compressed_blocks(&ffn_path)?
            } else {
                Self::create_dummy_blocks(16)? // 16ê°œ ë¸”ë¡
            };
            
            // Layer Norm íŒŒë¼ë¯¸í„°ë“¤ (ëœë¤ ì´ˆê¸°í™”)
            let ln1_weight = vec![1.0; config.hidden_size];
            let ln1_bias = vec![0.0; config.hidden_size];
            let ln2_weight = vec![1.0; config.hidden_size];
            let ln2_bias = vec![0.0; config.hidden_size];
            
            layers.push(LayerWeights {
                attention_blocks,
                attention_shape: (config.hidden_size, config.hidden_size * 3),
                ffn_blocks,
                ffn_shape: (config.hidden_size, config.hidden_size * 4),
                ln1_weight,
                ln1_bias,
                ln2_weight,
                ln2_bias,
            });
        }
        
        Ok(layers)
    }
    
    /// ì••ì¶•ëœ ë¸”ë¡ë“¤ ë¡œë“œ
    fn load_compressed_blocks(path: &str) -> Result<Vec<HybridEncodedBlock>> {
        let content = fs::read_to_string(path)?;
        let data: serde_json::Value = serde_json::from_str(&content)?;
        
        if let Some(blocks) = data.get("blocks") {
            let compressed_blocks: Vec<HybridEncodedBlock> = serde_json::from_value(blocks.clone())?;
            Ok(compressed_blocks)
        } else {
            Ok(Vec::new())
        }
    }
    
    /// ë”ë¯¸ ë¸”ë¡ë“¤ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    fn create_dummy_blocks(count: usize) -> Result<Vec<HybridEncodedBlock>> {
        let mut encoder = HybridEncoder::new(100, TransformType::Dwt);
        let mut blocks = Vec::new();
        
        for _ in 0..count {
            // ì‘ì€ ëœë¤ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± í›„ ì••ì¶•
            let data: Vec<f32> = (0..64).map(|_| rand::random::<f32>() * 0.01).collect();
            let block = encoder.encode_block(&data, 8, 8);
            blocks.push(block);
        }
        
        Ok(blocks)
    }
    
    /// NumPy ë§¤íŠ¸ë¦­ìŠ¤ ë¡œë“œ
    fn load_numpy_matrix(path: &str) -> Result<DMatrix<f32>> {
        println!("ğŸ“‚ NumPy ë§¤íŠ¸ë¦­ìŠ¤ ë¡œë“œ: {}", path);
        // ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” npy íŒŒì¼ íŒŒì‹± í•„ìš”
        // ì§€ê¸ˆì€ ì ë‹¹í•œ í¬ê¸°ì˜ ëœë¤ ë§¤íŠ¸ë¦­ìŠ¤ ë°˜í™˜
        Ok(DMatrix::from_fn(1000, 768, |_, _| {
            (rand::random::<f32>() - 0.5) * 0.02
        }))
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    println!("ğŸ‡°ğŸ‡· === í•œêµ­ì–´ RBE ì¶”ë¡  ì—”ì§„ ===");
    println!("ë”ë¯¸ ë°ì´í„° ì—†ì´ ìˆœìˆ˜ í•œêµ­ì–´ ì§ˆë¬¸/ë‹µë³€ ì‹œìŠ¤í…œ\n");
    
    // ì—”ì§„ ì´ˆê¸°í™”
    let engine = KoreanRBEEngine::new()?;
    
    println!("\nğŸ’¬ í•œêµ­ì–´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”! (ì¢…ë£Œ: 'exit')");
    println!("ğŸ¯ RBE ì••ì¶• ê¸°ë°˜ ê³ ì„±ëŠ¥ ì¶”ë¡ ");
    println!("ğŸ“ ì˜¨ì „í•œ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€\n");
    
    let stdin = io::stdin();
    loop {
        print!("ì§ˆë¬¸: ");
        io::stdout().flush()?;
        
        let mut input = String::new();
        stdin.read_line(&mut input)?;
        let input = input.trim();
        
        if input == "exit" || input == "quit" || input == "ì¢…ë£Œ" {
            println!("ğŸ‘‹ í•œêµ­ì–´ RBE ì—”ì§„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.");
            break;
        }
        
        if input.is_empty() {
            continue;
        }
        
        println!(); // ë¹ˆ ì¤„
        let start = Instant::now();
        
        match engine.generate_korean(input, 30, 0.7) {
            Ok(response) => {
                let duration = start.elapsed();
                println!("ğŸ¯ ë‹µë³€: {}", response);
                println!("â±ï¸ ìƒì„± ì‹œê°„: {:.2}ì´ˆ", duration.as_secs_f32());
                println!("ğŸ—œï¸ RBE ì••ì¶•ë¥ : 16384:1\n");
            }
            Err(e) => {
                println!("âŒ ì˜¤ë¥˜: {}\n", e);
            }
        }
    }
    
    Ok(())
} 