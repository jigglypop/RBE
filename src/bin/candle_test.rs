use anyhow::Result;
use candle_core::{Device, Tensor, DType};
use candle_nn;
use tokenizers::Tokenizer;
use std::io::{self, Write};
use std::time::Instant;
use std::path::Path;

/// Candleì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ëª¨ë¸
struct CandleTestModel {
    tokenizer: Tokenizer,
    device: Device,
    vocab_size: usize,
}

impl CandleTestModel {
    /// ê°„ë‹¨í•œ Candle í…ŒìŠ¤íŠ¸ ëª¨ë¸ ìƒì„±
    fn new(tokenizer_path: &str) -> Result<Self> {
        println!("ğŸ•¯ï¸ Candle í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì´ˆê¸°í™”...");
        println!("   - í† í¬ë‚˜ì´ì €: {}", tokenizer_path);
        
        // 1. ë””ë°”ì´ìŠ¤ ì„¤ì • (CPU)
        let device = Device::Cpu;
        println!("âœ… ë””ë°”ì´ìŠ¤: CPU");
        
        // 2. í† í¬ë‚˜ì´ì € ë¡œë“œ
        let tokenizer = Tokenizer::from_file(tokenizer_path)
            .map_err(|e| anyhow::anyhow!("í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {:?}", e))?;
        let vocab_size = tokenizer.get_vocab_size(false);
        println!("âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ: {} ì–´íœ˜", vocab_size);
        
        println!("âœ… Candle í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!");
        
        Ok(Self {
            tokenizer,
            device,
            vocab_size,
        })
    }
    
    /// ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± (ê¸°ë³¸ Candle ë™ì‘ í…ŒìŠ¤íŠ¸)
    fn generate_text(&self, prompt: &str, max_tokens: usize) -> Result<String> {
        println!("\nğŸ’­ Candle ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸: '{}'", prompt);
        
        // 1. í† í¬ë‚˜ì´ì§•
        let encoding = self.tokenizer.encode(prompt, false)
            .map_err(|e| anyhow::anyhow!("í† í¬ë‚˜ì´ì§• ì‹¤íŒ¨: {:?}", e))?;
        let mut token_ids: Vec<u32> = encoding.get_ids().to_vec();
        
        println!("ğŸ”¤ ì´ˆê¸° í† í° ìˆ˜: {}", token_ids.len());
        
        // 2. ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
        for step in 0..max_tokens {
            let next_token = self.simple_forward(&token_ids)?;
            
            // EOS ì²´í¬
            if next_token == 1 || next_token == 0 {
                break;
            }
            
            token_ids.push(next_token);
            
            // ì§„í–‰ ìƒí™© ì¶œë ¥
            if step % 3 == 0 {
                let partial = self.tokenizer.decode(&token_ids, true)
                    .unwrap_or_else(|_| "ë””ì½”ë”© ì˜¤ë¥˜".to_string());
                println!("ğŸ“ ë‹¨ê³„ {}: {}", step, partial);
            }
        }
        
        // 3. ìµœì¢… ë””ì½”ë”©
        let result = self.tokenizer.decode(&token_ids, true)
            .map_err(|e| anyhow::anyhow!("ë””ì½”ë”© ì‹¤íŒ¨: {:?}", e))?;
        
        Ok(result)
    }
    
    /// ê°„ë‹¨í•œ forward pass (Candle í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸)
    fn simple_forward(&self, token_ids: &[u32]) -> Result<u32> {
        // ê¸°ë³¸ í…ì„œ ì—°ì‚°ìœ¼ë¡œ ë‹¤ìŒ í† í° ìƒì„± (ëœë¤)
        let input_len = token_ids.len();
        
        // ê°„ë‹¨í•œ ê°€ì¤‘ì¹˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (ì„ë² ë”© ì‹œë®¬ë ˆì´ì…˜) - F32 ëª…ì‹œ
        let weights = Tensor::randn(0.0f32, 1.0f32, (self.vocab_size, 768), &self.device)?
            .to_dtype(DType::F32)?;
        
        // ì…ë ¥ í† í°ì„ ì›í•« ë²¡í„°ë¡œ ë³€í™˜
        let last_token = token_ids[input_len - 1] as usize % self.vocab_size;
        let mut input_vec = vec![0.0f32; self.vocab_size];
        input_vec[last_token] = 1.0;
        
        let input_tensor = Tensor::from_slice(&input_vec, (1, self.vocab_size), &self.device)?
            .to_dtype(DType::F32)?;
        
        // ê°„ë‹¨í•œ ë§¤íŠ¸ë¦­ìŠ¤ ê³±ì…ˆ
        let hidden = input_tensor.matmul(&weights)?;
        
        // ì¶œë ¥ ë ˆì´ì–´ (ì„ì‹œ) - F32 ëª…ì‹œ
        let output_weights = Tensor::randn(0.0f32, 1.0f32, (768, self.vocab_size), &self.device)?
            .to_dtype(DType::F32)?;
        let logits = hidden.matmul(&output_weights)?;
        
        // ì†Œí”„íŠ¸ë§¥ìŠ¤ + ìƒ˜í”Œë§ (ê°„ë‹¨í•œ argmax)
        let probs = candle_nn::ops::softmax(&logits, 1)?;
        let next_token_tensor = probs.argmax(1)?;
        
        // 1ì°¨ì› í…ì„œì—ì„œ ì²« ë²ˆì§¸ ìš”ì†Œ ì¶”ì¶œ
        let next_token_array = next_token_tensor.to_vec1::<u32>()?;
        let next_token = next_token_array[0];
        
        Ok(next_token % (self.vocab_size as u32))
    }
    
    /// ëª¨ë¸ ì •ë³´ ì¶œë ¥
    fn print_model_info(&self) {
        println!("\nğŸ“Š Candle í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì •ë³´:");
        println!("  ğŸ•¯ï¸ í”„ë ˆì„ì›Œí¬: Candle (Rust ë„¤ì´í‹°ë¸Œ)");
        println!("  ğŸ”¤ ì–´íœ˜ í¬ê¸°: {}", self.vocab_size);
        println!("  âš¡ ë””ë°”ì´ìŠ¤: {:?}", self.device);
        println!("  ğŸ§ª ê¸°ë³¸ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸ ëª¨ë“œ");
        println!("  âœ… Candle í”„ë ˆì„ì›Œí¬ ë™ì‘ í™•ì¸");
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    println!("ğŸ‡°ğŸ‡· === Candle í”„ë ˆì„ì›Œí¬ ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸ ===");
    println!("Candleì˜ í…ì„œ ì—°ì‚°ê³¼ í† í¬ë‚˜ì´ì € ë™ì‘ í™•ì¸\n");
    
    let tokenizer_path = "./models/skt-kogpt2-base-v2/tokenizer.json";
    
    // íŒŒì¼ ì¡´ì¬ í™•ì¸
    let tokenizer_exists = Path::new(tokenizer_path).exists();
    
    println!("ğŸ“‹ íŒŒì¼ í™•ì¸:");
    println!("   - í† í¬ë‚˜ì´ì €: {} ({})", tokenizer_path, 
             if tokenizer_exists { "ì¡´ì¬" } else { "âŒ ì—†ìŒ" });
    
    if !tokenizer_exists {
        return Err(anyhow::anyhow!("í† í¬ë‚˜ì´ì € íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."));
    }
    
    // Candle í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì´ˆê¸°í™”
    let model = CandleTestModel::new(tokenizer_path)?;
    model.print_model_info();
    
    println!("\nğŸ’¬ Candle ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸ ì‹œì‘! (ì¢…ë£Œ: 'exit')");
    println!("âš ï¸ ëœë¤ ê°€ì¤‘ì¹˜ë¡œ Candle í…ì„œ ì—°ì‚° ë™ì‘ í™•ì¸");

    let stdin = io::stdin();
    loop {
        print!("\nì§ˆë¬¸: ");
        io::stdout().flush()?;
        
        let mut input = String::new();
        stdin.read_line(&mut input)?;
        let input = input.trim();
        
        if input == "exit" || input == "quit" || input == "ì¢…ë£Œ" {
            println!("ğŸ‘‹ Candle í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.");
            break;
        }
        
        if input.is_empty() {
            continue;
        }

        let start = Instant::now();
        
        match model.generate_text(input, 10) {
            Ok(response) => {
                let duration = start.elapsed();
                
                println!("ğŸ¯ Candle í…ŒìŠ¤íŠ¸ ê²°ê³¼: {}", response);
                println!("â±ï¸ ì²˜ë¦¬ ì‹œê°„: {:.2}ì´ˆ", duration.as_secs_f32());
                println!("ğŸ•¯ï¸ Candle í…ì„œ ì—°ì‚° ì •ìƒ ë™ì‘");
            }
            Err(e) => {
                println!("âŒ ì˜¤ë¥˜: {}", e);
            }
        }
    }

    Ok(())
} 