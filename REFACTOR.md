현재 RBE 저장소는 PDF 논문 대신 README와 Markdown 문서에 논문의 내용과 코드가 통합돼 있습니다.  핵심은 `Packed128`(hi‑비트 + lo‑실수 파라미터)을 이용해 **가중치를 즉석에서 생성하는 융합 연산**과 **상태‑전이 미분**을 구현한 점입니다.  가중치를 계산하는 `fused_forward` 함수는 좌표를 정규화하고 거리 / 각도를 계산한 뒤 상태에 따라 sin / cos / tanh / sech² / exp / log / 1/x / 다항식을 적용하는 방식으로 동작합니다.  역전파에서는 각 위치별로 상태 비트를 업데이트하고 lo 파라미터(r, θ)에 대한 수치 미분을 수행합니다.  레이어 구현에서는 블록별로 모든 행과 열을 순회하며 가중치를 생성하고 곱셈을 수행하기 때문에 계산 비용이 매우 큽니다.  다음과 같은 부분들이 비트 연산만으로 해결되지 않는 병목으로 나타났습니다.

### 코드/알고리즘 분석 및 병목

* **높은 연산복잡도:** `fused_forward`는 각 좌표마다 `sqrt`, `atan2`, `sin`, `cos`, `tanh`, `exp` 등 부동소수점 함수를 호출하며, 상태에 따라 분기합니다.  이러한 transcendental 연산은 비트연산 대비 수백 배 느립니다.
* **수치 미분:** 역전파에서 r, θ에 대한 그래디언트를 계산할 때 `ε=10⁻⁵`를 사용하여 네 번의 `fused_forward` 호출로 차분을 구합니다.  이는 매 weight마다 추가 연산 4회를 요구하므로 상당한 병목이 됩니다.
* **전체 행렬 복원:** 하이브리드 residual 처리에서 `calculate_residual_row_dot_product`는 잔차를 복원하기 위해 전체 블록을 IDCT/IDWT로 디코딩한 뒤 다시 dot-product를 수행합니다. 문서에도 “성능을 위해서는 수학적 성질을 활용해야 하지만 현재는 단순히 블록을 복원한다”고 명시돼 있어 큰 비용을 초래합니다.
* **SVD 및 정렬:** 인코더는 각 블록의 RBE 파라미터를 SVD로 추정하고 잔차 계수를 절댓값 기준으로 정렬합니다. 이는 학습 단계에서 오프라인 작업이지만 매우 느린 연산입니다.

### 10× 이상의 속도 향상을 위한 설계 변경 제안

1. **Transcendental 함수의 근사화:**  8개의 상태 함수에서 `sin`, `cos`, `tanh`, `exp`, `log`, `1/x` 등을 직접 호출하지 않고, 정수 기반 CORDIC 알고리즘이나 다항식 근사(LUT + 선형보간)를 사용하면 연산당 수십 배의 속도 향상을 얻을 수 있습니다.  예를 들어 `Packed64::compute_weight`는 회전 비트열을 사용하여 sin/cos와 tanh를 CORDIC 방식으로 계산합니다.  이를 확장하여 `fused_forward`의 모든 상태에 대해 비트시프트와 덧셈만으로 근사 계산을 수행하고, lo 파라미터(r, θ)는 고정‑소수점 형식으로 처리하면 부동소수점 연산을 크게 줄일 수 있습니다.
2. **좌표 및 기본값 선계산:**  레이어의 행렬 크기와 블록 크기가 고정되어 있으므로 `(x_norm, y_norm)`, `dist`, `atan2(y_norm, x_norm)` 등은 미리 테이블로 계산해 두고 재사용할 수 있습니다.  `fused_forward`는 r과 θ만 변하므로 좌표별 입력값을 캐시하면 내부 루프에서 반복적인 `sqrt`와 나눗셈을 제거할 수 있습니다.
3. **수치 미분 제거:**  코드에는 이미 r과 θ에 대한 해석적 미분 함수(`analytical_gradient_r`, `analytical_gradient_theta`)가 구현돼 있으나, `fused_backward_precise`에서는 사용하지 않고 있습니다.  역전파 시 차분 대신 해석적 미분을 적용하면 weight당 네 번의 `fused_forward` 호출을 단 한 번의 계산으로 대체할 수 있으며, 이는 즉시 4× 이상의 속도 향상을 제공합니다.
4. **가중치와 그래디언트 동시 계산:**  가중치와 두 미분을 동시에 계산하는 함수로 분기와 기초값 계산을 한 번만 수행하도록 하여 메모리 접근을 줄입니다.  예를 들어 `(value, dr, dθ)`를 반환하는 `fused_forward_with_grad`를 작성하고, 내부에서 상태와 좌표에 따른 값과 미분을 모두 계산하여 재활용합니다.
5. **잔차 dot‑product의 변환 도메인 계산:**  `calculate_residual_row_dot_product`는 현재 전체 residual 블록을 복원하여 곱셈을 수행합니다.  대신 x‑슬라이스에 대해 DCT/DWT를 적용하고 top‑k 잔차와 곱한 뒤 역변환 없이 바로 합산하면 O(n²) 복원 비용을 O(k log n) 수준으로 줄일 수 있습니다.  특히 고정 블록 크기에서는 FFT 기반 합성곱(Convolution Theorem)을 통해 이를 수행할 수 있습니다.
6. **SIMD 및 병렬화:**  루프에서 독립적인 열/행에 대한 계산은 SIMD 벡터화에 적합합니다.  Rust의 `packed_simd` 또는 LLVM intrinsics를 사용하여 가중치 생성과 곱셈을 한 번에 8\~16개씩 처리하면 CPU 활용률을 높일 수 있습니다.  또한 현재 인코더만 Rayon을 사용하므로 forward/backward 루프에도 `par_iter`를 도입하여 블록 수준의 병렬화를 추가합니다.
7. **정수 양자화:**  r과 θ를 부동소수점 대신 정수로 양자화하여 bit‑shift 연산으로 스케일링하고, 연속 파라미터 업데이트도 정수 범위에서 클램핑하면 메모리 대역폭과 연산비용을 줄일 수 있습니다.  예를 들어 r을 Q0.20 형식으로, θ를 Q1.23 형식으로 저장하고 업데이트할 때 적절히 비트 이동을 통해 연산하면 빠릅니다.
8. **에러 허용 범위 조정:**  학습 시 어느 정도 오차를 허용할 수 있다면 `block_size`를 줄이고 `k_coeffs`를 줄여 residual 수를 최소화하면 뒤쪽 연산 비용이 감소합니다.  README의 분석에 따르면 64×64 블록에서 4.2배의 성능 향상이 가능함을 보여 줍니다.

위의 개선안들을 단계별로 적용하면 `fused_backward`에서만 4~~6배, 상태 함수 근사화와 벡터화에서 2~~4배, 잔차 처리 개선에서 2배 정도의 성능 향상을 기대할 수 있습니다.  이들을 조합하면 전체 레이어 연산이 최소 **10× 이상** 빨라질 가능성이 있으며, 메모리 사용량을 유지한 채 RBE의 장점을 그대로 활용할 수 있습니다.
